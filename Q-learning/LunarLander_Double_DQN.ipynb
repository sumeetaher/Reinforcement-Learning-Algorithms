{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Jayesh of RL ass2 Lunar Lander.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "\"I/we certify that the code and data in this assignment were generated independently, using only the tools and resources defined in the course and that I/we did not receive any external help, coaching or contributions during the production of this work.\""
      ],
      "metadata": {
        "id": "7dzJC-EvtKy8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install Box2D"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7LMstWlsj6Kf",
        "outputId": "803091be-9615-4869-9c8b-135b18aebe02"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting Box2D\n",
            "  Downloading Box2D-2.3.10-cp37-cp37m-manylinux1_x86_64.whl (1.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.3 MB 5.3 MB/s \n",
            "\u001b[?25hInstalling collected packages: Box2D\n",
            "Successfully installed Box2D-2.3.10\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Implementing Double DQN on LunarLander environment"
      ],
      "metadata": {
        "id": "3qhINusyEw0n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import gym\n",
        "from gym import spaces"
      ],
      "metadata": {
        "id": "CoYEMa9VEuwE"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import random, math, time\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import *\n",
        "from tensorflow.keras.optimizers import *\n",
        "import matplotlib\n",
        "import tensorflow.keras.backend as K"
      ],
      "metadata": {
        "id": "Y2CqtmQtnedJ"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "lunar_env = gym.make('LunarLander-v2')\n",
        "lunar_env.reset()\n",
        "print(lunar_env.action_space.n)\n",
        "print(lunar_env.observation_space)\n",
        "print(lunar_env.observation_space.high)\n",
        "print(lunar_env.observation_space.low)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gw4M-yBpEzZd",
        "outputId": "18353ef5-816a-41ef-ef88-0d306db20ea7"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4\n",
            "Box(-inf, inf, (8,), float32)\n",
            "[inf inf inf inf inf inf inf inf]\n",
            "[-inf -inf -inf -inf -inf -inf -inf -inf]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This environment has the following properties:\n",
        "1.   Reward Solved is 200 points\n",
        "2.   Four discrete actions possible"
      ],
      "metadata": {
        "id": "c400XQlXkXz9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ReplayBuffer(object):\n",
        "\n",
        "    def __init__(self, size):\n",
        "      self.size = size\n",
        "      self.buffer = []\n",
        "      self.idx = 0\n",
        "\n",
        "    def add(self,state,action,reward,newstate,done):\n",
        "      if len(self.buffer) >= self.size:\n",
        "        self.buffer[self.idx] = (state,action,reward,newstate,done)\n",
        "      else:\n",
        "          self.buffer.append((state,action,reward,newstate,done))\n",
        "\n",
        "      self.idx+=1\n",
        "\n",
        "      if self.idx == self.size:\n",
        "        self.idx = 0\n",
        "\n",
        "    def sample(self, batch_size):\n",
        "      size_sample = min(len(self.buffer), batch_size)\n",
        "      return random.sample(self.buffer, size_sample)\n",
        "      "
      ],
      "metadata": {
        "id": "XYyOizq2E4zA"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Agent:\n",
        "  def __init__(self, env):\n",
        "    self.env = env\n",
        "    self.observation_space = env.observation_space\n",
        "    self.action_space = env.action_space\n",
        "\n",
        "  def step(self, observation):\n",
        "    return np.random.choice(self.action_space.n)"
      ],
      "metadata": {
        "id": "Si8HzVmNE6LS"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Below is the application of Double DQN on lunar lander"
      ],
      "metadata": {
        "id": "BasV0AuX7RfD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class DDQLearning:\n",
        "    def __init__(self,env,agent):\n",
        "        self.env = env\n",
        "        self.agent = agent\n",
        "        self.observation_space = env.observation_space\n",
        "        self.action_space = env.action_space\n",
        "        self.DDepsilon_decay = []\n",
        "        self.ddqn_reward_train = []\n",
        "        self.DDlosses = []\n",
        "        \n",
        "    def greedy_act_max(self,obs):\n",
        "        return np.argmax(self.model_target(obs))\n",
        "        \n",
        "    def policy(self,epsilon,obs):\n",
        "        return random.choices([np.random.randint(self.action_space.n), self.greedy_act_max(obs)], weights =(epsilon,1-epsilon),k=1)[0]\n",
        "    \n",
        "    def max_Qval(self,state):\n",
        "        return np.argmax(self.target_qtable, axis=1)[state]\n",
        "\n",
        "    def learning_network_model(self,lr,input_state_dim,output_action_dim):\n",
        "        model = Sequential()\n",
        "        model.add(Dense(32, input_dim=input_state_dim, activation='relu'))\n",
        "        model.add(Dense(64, activation='relu'))\n",
        "        model.add(Dense(output_action_dim, activation='linear'))\n",
        "        opt = tf.keras.optimizers.Adam(learning_rate=lr)\n",
        "        model.compile(loss='mse', optimizer=opt)\n",
        "        return model\n",
        "        \n",
        "    def train(self,episodes,gamma,alfa_lr,decay_factor,replay_buffer_size=2000,minibatch_size=128):\n",
        "        epsilon = 1\n",
        "        episodes = episodes\n",
        "        rbuffer = ReplayBuffer(replay_buffer_size)\n",
        "        obs = self.env.reset()\n",
        "        obs_size = 8\n",
        "        action_size = self.env.action_space.n\n",
        "        self.model_policy = self.learning_network_model(alfa_lr,obs_size,action_size)\n",
        "        self.model_target = self.learning_network_model(alfa_lr,obs_size,action_size)\n",
        "        self.model_target.set_weights(self.model_policy.get_weights())\n",
        "        overall_step = 0\n",
        "        for eps_n in np.arange(episodes):\n",
        "            obs = self.env.reset()\n",
        "            done_iter = False\n",
        "            self.DDepsilon_decay.append(epsilon)\n",
        "            #print(\"The episode no. is \" + str(eps_n))\n",
        "            cumm_reward=0\n",
        "            step_no=0\n",
        "\n",
        "            while not done_iter:\n",
        "              agent_pnow = np.argmax(obs)\n",
        "              action = int(self.policy(epsilon,obs.reshape(1,obs_size)))\n",
        "              obs_next, reward, done_iter, info = self.env.step(action)\n",
        "              cumm_reward += (gamma**(step_no))*reward\n",
        "\n",
        "              rbuffer.add(obs.reshape(1,obs_size),action,reward,obs_next.reshape(1,obs_size), done_iter)\n",
        "              step_no+=1\n",
        "              overall_step += 1\n",
        "              obs = obs_next\n",
        "              \n",
        "              batch = rbuffer.sample(minibatch_size)\n",
        "              batch_size = len(batch)\n",
        "              if batch_size == minibatch_size:\n",
        "                curr_pos_batch = np.array([ sample_state[0] for sample_state in batch ])\n",
        "                if step_no%5==0:\n",
        "                  state_next = tf.stack([s2 for (s1,a,r,s2,d) in batch])\n",
        "                  curr_state = tf.stack([s1 for (s1,a,r,s2,d) in batch])\n",
        "                  action_ = tf.stack([a for (s1,a,r,s2,d) in batch])\n",
        "                  reward_ = tf.cast(tf.stack([r for (s1,a,r,s2,d) in batch]), tf.float32)\n",
        "                  done_ = tf.cast(tf.stack([d for (s1,a,r,s2,d) in batch]), tf.float32)\n",
        "                  if True:\n",
        "                    next_q = self.model_policy.predict(tf.reshape(state_next,(minibatch_size,obs_size)))\n",
        "                    #print(\"7\")\n",
        "                    max_a = tf.math.argmax(next_q, 1)\n",
        "                    #print(\"8\")\n",
        "                    double_q = self.model_target.predict(tf.reshape(state_next,(minibatch_size,obs_size)))\n",
        "                    #print(\"9\")\n",
        "                    target_y = reward_  + gamma*(1-done_)*(tf.gather(double_q[0], max_a).numpy())\n",
        "                    #print(\"10\")\n",
        " \n",
        "                  #print(\"11\")\n",
        "                  #print(\"12\")\n",
        "                  x = tf.reshape(curr_state,(minibatch_size,obs_size))\n",
        "                  #print(\"13\")\n",
        "                  q_predicted = self.model_policy.predict(tf.reshape(curr_state,(minibatch_size,obs_size)))\n",
        "                  dept_action = tf.expand_dims(action_, 1)    #adding depth dimension to the action tensor\n",
        "                  #print(\"14\", b_2)\n",
        "                  index_tensor = tf.expand_dims(tf.range(tf.shape(action_)[0]), 1)   #adding depth dimension to a new tensor with shape as action tensor\n",
        "                  #print(\"15\", range)\n",
        "                  index_to_update = tf.concat([index_tensor, dept_action], 1)        #adding depth dimension to a new tensor with shape as action tensor\n",
        "                  #print(\"16\")\n",
        "                  y = tf.tensor_scatter_nd_update(q_predicted, index_to_update, target_y)\n",
        "                  #print(\"14\")\n",
        "                  #print(tf.shape(x) ,tf.shape(y))\n",
        "                  sequential_model = self.model_policy.fit(x, y, batch_size=minibatch_size, epochs=1, verbose=0)\n",
        "                  self.DDlosses.append(sequential_model.history['loss'])\n",
        "                  #print(\"16\")\n",
        "                  if overall_step%400 ==0:\n",
        "                    self.model_target.set_weights(self.model_policy.get_weights())\n",
        "\n",
        "            if epsilon > 0.001 : epsilon = epsilon*decay_factor\n",
        "            self.ddqn_reward_train.append(cumm_reward)\n",
        "            print(\"cummulative reward is \" + str(cumm_reward) + \" for episode no. \" + str(eps_n + 1)  )  \n",
        "            \n",
        "            "
      ],
      "metadata": {
        "id": "k4kz5r1nr2Ab"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "agent = Agent(lunar_env)\n",
        "\n",
        "epsilon = 1\n",
        "number_of_episodes = 1000\n",
        "decay_factor = round((0.01/epsilon)**(1/number_of_episodes),4)\n",
        "\n",
        "ddql = DDQLearning(lunar_env,agent)"
      ],
      "metadata": {
        "id": "Whcex8qI7puJ"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ddql.train(episodes = number_of_episodes,gamma = 0.99, alfa_lr = 0.001, decay_factor=decay_factor)"
      ],
      "metadata": {
        "id": "_oDQ9AG68ell",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "d9d793bb-c9c2-45e6-f546-d1844b66a363"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 44.6350\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 1.6559\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 10.3283\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 2.4817\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.4231\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 3.4617\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.0185\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 4.1206\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 19.0745\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 2.7082\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 2.9590\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 2.3245\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 1.8347\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.1468\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.3292\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 1.0923\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.9205\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.1848\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.6486\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.3961\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 4.3655\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.9619\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 2.1970\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 22.9961\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 1.0098\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 466.8770\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 15.1320\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 3.2624\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 1.0393\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 3.4206\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 18.4609\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.1426\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 5.8535\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 28.3675\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 27.9387\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 9.7375\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 46.4437\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 5.8237\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 20.1359\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 30.3783\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 6.6992\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 17.6797\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 8.3140\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 6.8432\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 14.3595\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 5.8465\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 9.3051\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 21.2488\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 18.7090\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 2.1199\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 16.4402\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 5.3004\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 4.5926\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 3.7488\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 4.9950\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 8.9923\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 12.0768\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 4.2533\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.7915\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.3417\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.3716\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.2161\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.2639\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 1.3288\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 3.8855\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 16.0732\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.8363\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 7.1541\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.2760\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 3.1057\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.0938\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.7121\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 3.9919\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 17.6118\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.8478\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 4.6370\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 2.3711\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 16.1577\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 18.6898\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 2.2921\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.4909\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.4930\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 5.3721\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 3.1861\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 16.4486\n",
            "cummulative reward is -19.946917447413618 for episode no. 582\n",
            "The episode no. is 582\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 2.3928\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.9592\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 2.3283\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.4194\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.9487\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 10.1303\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.9693\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 5.7485\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 3.1807\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 12.1331\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 16.5770\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 614.4034\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.5841\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.1173\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.2419\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.2748\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 18.7281\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 1.7364\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 5.3706\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.9116\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 4.0986\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 354.5916\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 7.6086\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 6.5003\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 8.5155\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 6.0135\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 3.7755\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 5.0001\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 10.4428\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 9.8052\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 13.4395\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 6.3540\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 17.8060\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 3.3595\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 7.0731\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 10.5668\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 4.4417\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 5.5786\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 4.5851\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 5.8310\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 6.3161\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 3.9392\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 1.3895\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 2.5351\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 6.5240\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 20.7096\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 3.0052\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 2.8035\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 2.2112\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 3.5129\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.9963\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 2.3839\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 2.1582\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.6165\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 3.1357\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 2.1146\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.1811\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 10.0828\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 98.7424\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 2.1460\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.5333\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.0758\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 88.2103\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 2.7584\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 9.6327\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 2.1106\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 4.2609\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.8723\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.9829\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.9299\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.2182\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 9.9816\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.9583\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.8146\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 2.5108\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.5589\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 4.2433\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 2.3164\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 3.6296\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 11.0738\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 1.3069\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 1.4869\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 13.0022\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 2.2023\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 2.5698\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.8548\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 10.8820\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 3.4282\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 1.1012\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.7876\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.8838\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 10.0455\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 6.9669\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.9723\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 5.7505\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.9176\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.8335\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 8.3711\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.2520\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 36.1719\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.3555\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.3007\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 4.1822\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.2165\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.3152\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.6897\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 151.9778\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 1.4905\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.5560\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 1.1169\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 2.0716\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6637\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 18.4808\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 2.9574\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.8345\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.9174\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.0692\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 11.3789\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.3737\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 10.3977\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.8657\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.5049\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 1.0304\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 22.5809\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 17.9651\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.0211\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 10.7140\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 9.4775\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.5880\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 12.2252\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 1.2691\n",
            "cummulative reward is 6.48348148645243 for episode no. 583\n",
            "The episode no. is 583\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 4.0165\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.2536\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.0204\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 22.4688\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 3.3556\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 2.2061\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 12.6856\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 2.5740\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 28.9702\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 3.9813\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.0077\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 1.6669\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 1.0522\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 3.1828\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 5.6199\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 3.3267\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 2.1049\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 2.7403\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 4.0440\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 4.0185\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.7559\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.4325\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.8524\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 5.5009\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 2.7692\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6489\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.0781\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 3.4453\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.4243\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.4890\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 3.2279\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 2.7532\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.7945\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 1.4713\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 3.8851\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.1499\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.9238\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 3.5314\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 2.3119\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.1847\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 3.2658\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 1.4096\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.8536\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.7281\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.9856\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.0028\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.6448\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.2968\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.2790\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.7116\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.5575\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 2.4809\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.8222\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.0614\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.8047\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.5354\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.8394\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.5735\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.2888\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.2346\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.6931\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 1.2289\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 1.2283\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.9563\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.7012\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 6.1627\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.6546\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.7020\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.0712\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.1931\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.0972\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 3.4730\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.5931\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.8867\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.0076\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.5641\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.2404\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.6921\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.7130\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.0719\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.1060\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.7591\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 2.6553\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 3.9800\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.3043\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.8984\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.7021\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.7508\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.4720\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.5377\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 2.0477\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 2.6306\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 2.0453\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 2.5234\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 1.0473\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.7433\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.9664\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 1.4666\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.4993\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.5605\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.1728\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 6.3844\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.9572\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.8651\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 6.0303\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 1.2946\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.3454\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.3055\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.7422\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.0060\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 33.6476\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 2.5573\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.2477\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6819\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.2439\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.0182\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 1.8661\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.8109\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 3.4543\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 5.7323\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 3.0236\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.7208\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.9582\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.3669\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 2.1140\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.9110\n",
            "cummulative reward is -18.15240659937573 for episode no. 584\n",
            "The episode no. is 584\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.9808\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.8359\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.6789\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.9261\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.9111\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 2.9721\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 2.4158\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.4656\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 2.0775\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 1.8201\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 1.9133\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 3.4657\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 2.3189\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.8289\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.8982\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.0473\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.0046\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 2.8407\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 3.4724\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.6399\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 2.8120\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 16.9307\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 8.3874\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.4989\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 2.3366\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.7283\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.9095\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 2.2106\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.9915\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.4422\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 2.9536\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 1.1272\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 2.3943\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.2344\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.0287\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 1.4448\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.4904\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.9486\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.3613\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.8730\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.1930\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.3153\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.2376\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.0710\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.4838\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.5240\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 1.7581\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.8954\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.0337\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.1525\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.9160\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 2.6728\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.7823\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 1.8119\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 2.2613\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 1.0654\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 5.5111\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.0388\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.8678\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.9912\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 2.3831\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 2.0710\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 1.9780\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.8953\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.7562\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 2.5567\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.9688\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.2831\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.2759\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.2767\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.1920\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 5.5229\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.2999\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 3.4568\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.7356\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.8945\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 4.7574\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.0733\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.9219\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.3102\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.9252\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.8311\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.3408\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.2590\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.9414\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.3587\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 2.5680\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.9005\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 3.9783\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.9828\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 1.6381\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.2873\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.5083\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 1.2104\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 3.3576\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 2.3705\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 3.9541\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 1.5940\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 2.2214\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 1.5709\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 2.3962\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 4.0100\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 1.5851\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.1853\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 1.5392\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.8657\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.9454\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.2189\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 2.2454\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 4.4413\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.5362\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 5.2933\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 2.0424\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 2.6131\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 1.6020\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 4.0551\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.3279\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.0065\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.9734\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.3267\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 2.9756\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.4545\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 2.1502\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.3257\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 2.0136\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.1777\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 3.4844\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.2847\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.9447\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.8845\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.9181\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.5058\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.6442\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.0465\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.0179\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.3926\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.0034\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 1.6883\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 1.1122\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.0470\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 2.2060\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 1.1793\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 2.5779\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.2356\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 3.0508\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.8964\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.6338\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.3137\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.6672\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.1782\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 1.1916\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.6239\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 1.1130\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 2.0218\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.8261\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.5537\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 2.6507\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 4.8005\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 2.1621\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 4.4071\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 3.1767\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 7.3419\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 27.2388\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.2720\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 15.9222\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.1465\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 1.0994\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 117.1767\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 2.0285\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 4.1967\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 5.7019\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.6577\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 4.1120\n",
            "cummulative reward is -31.396309560661706 for episode no. 585\n",
            "The episode no. is 585\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 9.0369\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 3.2674\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 4.0587\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 6.9461\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 2.8254\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 7.3536\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 4.2880\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 3.9528\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 5.5444\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 2.4352\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 8.7702\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 6.9550\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.3424\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 4.3582\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 2.5253\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 1.5336\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 6.0501\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.7051\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.0369\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 2.4795\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 3.5567\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 2.5495\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 1.5274\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 3.9793\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 2.0042\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 2.9172\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 1.2555\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 2.6766\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.9001\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 1.6209\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 4.6060\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.6479\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.7070\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 2.2736\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 3.8678\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 1.3383\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 2.4959\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 3.9676\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.7930\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 2.3618\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 1.0182\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.1461\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 4.1558\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.7199\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.5166\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 3.8831\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.5288\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.2715\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.6631\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 3.9786\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 2.0634\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 19.8399\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 3.0978\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 3.6318\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.7786\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 3.7645\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.0850\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 4.2390\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 1.6179\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.9954\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 4.9095\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 2.5750\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.4370\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.1084\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.5371\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.8637\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 18.7098\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 3.0638\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 2.1240\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 5.6698\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.5618\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.7764\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 2.3092\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.4575\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 6.2828\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 2.9221\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 2.4993\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.7776\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 3.8508\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 3.2614\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 2.5540\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.7406\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 1.7483\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.2333\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 4.5283\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 2.8707\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 1.7597\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 6.2897\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.3127\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.8699\n",
            "cummulative reward is -13.70219088855424 for episode no. 586\n",
            "The episode no. is 586\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 3.3466\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 3.0002\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 2.0777\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 2.3865\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 1.4572\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.4152\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 3.4336\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.3142\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 2.5186\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 2.9638\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 1.5883\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 8.4597\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 2.2387\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 2.2944\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 2.9679\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 2.7258\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 3.2013\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.9979\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.8353\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.8391\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.6778\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 4.8867\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.8681\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 1.5418\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 2.9705\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 9.6276\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 2.0890\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 42.2944\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.9690\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 4.3569\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 2.6545\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.3438\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 2.9166\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 2.6096\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.5874\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 2.4219\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 3.9689\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.3498\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 4.3514\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 3.1348\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.9951\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 2.4589\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.9528\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.6020\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.9412\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 3.0347\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.4608\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.3205\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 1.0081\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.7671\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.0945\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 2.3049\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.0718\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 3.5006\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 1.4049\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 1.8163\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.8789\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 2.1104\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 1.7912\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 2.4351\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.3415\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 2.7708\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.3415\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 4.4416\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.1448\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.2552\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.7246\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 5.3022\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 2.3552\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 3.4865\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.0445\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.5688\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.4018\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 1.4622\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.1955\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.3273\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.9645\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.4317\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.3371\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 3.0703\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.3748\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 18.9279\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.8506\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.6272\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 2.1586\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.7369\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.4453\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 2.0953\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.8244\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.3749\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 1.1666\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.7578\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.6828\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.0753\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 10.1298\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.0936\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 4.5803\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 2.6002\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 2.4554\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.4014\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 1.4531\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 3.3858\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.8242\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 3.8103\n",
            "cummulative reward is -24.15762829257464 for episode no. 587\n",
            "The episode no. is 587\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.6753\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 1.7786\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 2.9241\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 1.3280\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.6351\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 2.6031\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.3845\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.3892\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 3.0970\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 2.6538\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 5.4622\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 1.6909\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 2.3190\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 5.5592\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.1999\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.7757\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.0438\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.3162\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.1016\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 2.2021\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.3683\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 2.0177\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 2.8864\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.2967\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 2.4952\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.9936\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.4104\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.9392\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 4.4316\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.2010\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.2232\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.9889\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.0960\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 2.2472\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 2.0038\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 2.4989\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 3.7970\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.1719\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 1.6510\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.2057\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 2.1347\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.2519\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 1.8347\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.3467\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 1.2893\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.1011\n",
            "cummulative reward is -7.1557898015582655 for episode no. 588\n",
            "The episode no. is 588\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 2.1266\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 4.3763\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 4.3118\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 14.2554\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 2.2511\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.9529\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 1.7055\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.4435\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 2.9792\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 3.6633\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.9458\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 1.7450\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.2523\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.4612\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 1.6632\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.4093\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 2.4031\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 1.8512\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 2.2319\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 1.6103\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 4.4094\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.2626\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.7363\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.1868\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 2.6981\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 2.0968\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 2.9061\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 4.6317\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.9549\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.9570\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 2.0089\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 5.3691\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.4730\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.3179\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 2.1945\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 4.1843\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 2.0271\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.1954\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 2.1018\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.7304\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.9259\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 1.4404\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 2.5188\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 1.6729\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 3.7724\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 2.1212\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 3.9798\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 2.2087\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.8927\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.2996\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 4.3082\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 1.6634\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 2.9456\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 3.0544\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 7.9329\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 2.2279\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 3.7867\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 1.6065\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.7921\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 2.7756\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 2.7655\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 2.9043\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.4685\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.5613\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.7357\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 2.1316\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 1.6698\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 7.1365\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 3.5783\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 2.1337\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 12.7614\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 3.3529\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 4.3236\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 2.8842\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 2.2533\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.1707\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 3.2257\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 1.2678\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 5.0948\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 2.0746\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 3.4256\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 3.4952\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 2.6079\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.9244\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 3.0599\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 7.1843\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 3.2327\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.8445\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 8.4736\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 2.2859\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 3.3621\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 5.7221\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 2.5578\n",
            "cummulative reward is 24.29863127241717 for episode no. 589\n",
            "The episode no. is 589\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 3.9756\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 4.0249\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 1.9606\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 56.7135\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 3.3112\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 8.0366\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 4.6367\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 2.9582\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 3.4152\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 4.9807\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 2.2306\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 5.6504\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 51.7363\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 3.6550\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 38.4173\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 2.9251\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 4.1975\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 2.8193\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 2.8238\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 3.5367\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 6.0363\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 3.8995\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 6.1300\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 5.5491\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 3.2170\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 4.9138\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 4.6670\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.9612\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 5.4450\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 4.0605\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 4.6194\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 7.0341\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 2.2725\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 2.6513\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.4639\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.6096\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 2.4957\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 3.0028\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 6.4237\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 3.1107\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 2.8829\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 3.4621\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 3.3403\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 5.4705\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 3.7564\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 3.0100\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 2.4942\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.6145\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 2.2970\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 2.3295\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 2.4706\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 3.1638\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 46.6394\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 4.9397\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 4.3710\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 2.5464\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 5.2269\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 4.9161\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 6.6284\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 3.4277\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 2.9419\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 2.3188\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 3.3282\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 4.3671\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 4.5964\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 5.3835\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 2.3166\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 2.8501\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 2.8847\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 3.0204\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 4.8247\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 4.3688\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 2.7997\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 2.0937\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 4.1928\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 4.3375\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 6.0799\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 4.4015\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.9328\n",
            "cummulative reward is 58.53814627040411 for episode no. 590\n",
            "The episode no. is 590\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 5.7547\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 3.9079\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.5201\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 5.3729\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 2.7893\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 2.7405\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 11.4833\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 3.4342\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 65.4437\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 3.1531\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 66.5194\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 3.7301\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 63.9899\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 2.9794\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 5.9053\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 2.3983\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 3.9537\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 4.0501\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 7.1186\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 3.5159\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 7.3060\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 2.4022\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 4.0788\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 4.8320\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 2.5256\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 2.0058\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 40.5073\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 6.4957\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 5.1765\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 3.8020\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 5.7789\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 3.6939\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 4.8335\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 14.0822\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 6.5388\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 5.1448\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 4.2364\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 3.8008\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 4.6647\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.8819\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 4.3137\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 2.0962\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 2.0137\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 1.6572\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 2.6894\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 3.3010\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 2.9436\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 4.8312\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 6.4852\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 2.9239\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 7.3066\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 3.7064\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 2.1667\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 4.5989\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 64.1857\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 2.2075\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 3.8106\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 3.0509\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 2.5917\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 3.6678\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 7.7652\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 2.3592\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 4.8880\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.6952\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 5.3470\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 49.5052\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 4.9527\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 3.9617\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 2.6444\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 9.1941\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 47.6230\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 2.9660\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 4.1251\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.4978\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 2.6475\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.8165\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 3.5876\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.7233\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 2.8950\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 2.5530\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 2.8679\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 5.8274\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 2.1095\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 3.8719\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 3.2556\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 2.7567\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 3.5868\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 11.3067\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 63.6237\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 9.3367\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 4.6121\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 3.9518\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 3.9741\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.4664\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 3.7154\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 3.0621\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 3.0800\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 3.4589\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 2.1351\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 50.3252\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 4.0391\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 3.6011\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 6.1817\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.7768\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 4.0250\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.9831\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 5.0013\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 4.3893\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 2.5142\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 5.5546\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 6.4323\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 5.3564\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 67.4175\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 3.2787\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 3.8853\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 3.3668\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 5.4983\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 18.0740\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 3.3888\n",
            "cummulative reward is -2.9454313956964517 for episode no. 591\n",
            "The episode no. is 591\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 3.5674\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 3.7017\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 3.8120\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 4.5356\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 123.2485\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 7.5710\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 5.7577\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 7.0668\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 4.0941\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 2.4643\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 4.0838\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 2.1021\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 4.4146\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 4.9388\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 2.1949\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 2.3520\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 2.8934\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 2.9478\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 2.7122\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 9.7820\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 4.6156\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 5.0091\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 3.0554\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 2.4721\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 2.5365\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 3.3743\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 6.5283\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 3.3202\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 3.1996\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 4.7401\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 3.7278\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 4.5114\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 2.2685\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 2.3476\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 3.1123\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 37.3138\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 3.8756\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 4.6465\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 8.5949\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 5.6875\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 66.0547\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 6.6452\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 5.2670\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 4.2547\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 5.2713\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 5.2423\n",
            "cummulative reward is 7.212335442866648 for episode no. 592\n",
            "The episode no. is 592\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 4.2271\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 2.3264\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 6.4930\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 6.0891\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 49.1307\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 5.6815\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 4.5396\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 3.9188\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 3.8009\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 2.3767\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 4.8329\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 3.7893\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 127.5537\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 4.0737\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 4.2896\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 4.1583\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 62.4632\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 5.7240\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 2.7489\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 2.6819\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 2.7868\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 2.4423\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 6.0825\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 6.8673\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 5.2317\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 2.9183\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 62.3441\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 5.3971\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 3.2039\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 4.5253\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 4.5266\n",
            "cummulative reward is -44.92337963799932 for episode no. 593\n",
            "The episode no. is 593\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 20.6429\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 3.8155\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 3.8694\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 4.7234\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 64.6242\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 5.3781\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 2.9924\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 2.8357\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 3.2019\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 3.3017\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 7.7835\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 3.7070\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 6.9373\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 4.7323\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 3.0964\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 40.4060\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 3.0412\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 3.3384\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 65.8031\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 125.8219\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 2.2654\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 64.0664\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 62.3578\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 3.4975\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 4.4231\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 3.6220\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.8796\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 3.6674\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 13.7272\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 3.9941\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 3.0066\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 2.8744\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 62.2889\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 6.9334\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 2.5722\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 11.1614\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 4.2021\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 3.8290\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 63.0834\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 3.0366\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 4.7170\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 64.3137\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 3.6301\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 3.5397\n",
            "cummulative reward is -7.829093499156957 for episode no. 594\n",
            "The episode no. is 594\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 4.3838\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 2.2979\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 13.4308\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 6.1549\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 45.5801\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 2.4431\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 2.8368\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 4.1293\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 3.1870\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 3.8938\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 7.0861\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 5.6897\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 3.5226\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 2.2675\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 5.9346\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 68.3196\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 63.1324\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 99.3984\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 3.6313\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 3.7051\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.6958\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 9.2346\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 2.4764\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 4.1693\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 7.7560\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 4.8713\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 62.8672\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 3.6896\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 8.7305\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 4.3932\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 64.4224\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 2.7755\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 64.8572\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 3.6250\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 4.7517\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 2.5825\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 2.7685\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 5.9853\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 3.7340\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 4.5514\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 17.6578\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 5.3510\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 2.4212\n",
            "cummulative reward is 4.077583756901275 for episode no. 595\n",
            "The episode no. is 595\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 7.0740\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 66.8239\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 2.9331\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 3.7168\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 3.2373\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 3.1216\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 65.2466\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 2.3673\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 3.2488\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 116.8954\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 3.5558\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 4.5835\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 4.3445\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 2.5264\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 63.4174\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 62.7897\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 8.8102\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 4.8453\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 3.5588\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 20.6516\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 3.8787\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 3.3847\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 5.0924\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 2.4493\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 5.8724\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 4.3000\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.8387\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 2.1412\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 6.3877\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 61.1337\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 3.8387\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 6.8290\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 61.7649\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 5.2311\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 5.1166\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 3.6085\n",
            "cummulative reward is -29.604685993772712 for episode no. 596\n",
            "The episode no. is 596\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 4.3774\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 4.0960\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 2.7878\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 3.6267\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 2.6255\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 4.4172\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 3.7654\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 2.9662\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 3.7270\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 6.8688\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 3.7053\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.8440\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 9.0426\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 2.0406\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 6.5800\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 3.1864\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 4.9557\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 4.0199\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 62.6141\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 63.7000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 68.5600\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.8286\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 4.0855\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 6.5252\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 2.6742\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 130.7599\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.8805\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 4.3038\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 4.4068\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 3.7696\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 64.1678\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 4.2201\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 4.0923\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 3.3108\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 3.5984\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 2.3825\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 3.3897\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 2.7994\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 4.0250\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 3.2672\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.7957\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.8304\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 3.2659\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 62.7380\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.7415\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 2.3038\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 62.4200\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 2.0708\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 28.2514\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 5.6557\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 2.9874\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 5.8453\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 2.3686\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 60.5048\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.2146\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 3.0330\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.7430\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 61.0242\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 2.9584\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 1.7424\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 13.0137\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 2.0616\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 2.7023\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 2.0046\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 4.4803\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 59.2539\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 1.8403\n",
            "cummulative reward is -43.18944483293606 for episode no. 597\n",
            "The episode no. is 597\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 2.1145\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 1.4202\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 4.5039\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.2550\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.7926\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 59.5980\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 3.3018\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.8494\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 4.0967\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.1871\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 2.1184\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 2.1267\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 7.8410\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 62.3354\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 4.7803\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 2.0439\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 3.6628\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 2.4549\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.1290\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 2.4583\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 2.0839\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 2.8140\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 2.3040\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 5.1107\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 1.7061\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 3.7965\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 6.4483\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 60.9336\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 2.3262\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 64.6017\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.1695\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.6401\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.6090\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 2.9829\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 2.8740\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 1.9504\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 1.5434\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 2.1091\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 2.2568\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 2.7338\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 2.0905\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.4215\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 3.2832\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 3.1639\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 2.5983\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 3.5386\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 3.8508\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 2.8744\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 2.8058\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 2.0442\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 5.2322\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.5969\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.7060\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 4.5438\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 3.4638\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 2.0699\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 3.7361\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 63.6582\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 12.8300\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 2.6182\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 2.6572\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 4.3911\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 2.7536\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 2.9013\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 3.2173\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 3.6933\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.5880\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 7.1297\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 3.4053\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 5.2176\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 2.5968\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 60.8827\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 2.2652\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 3.2903\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.5722\n",
            "cummulative reward is -51.531195935404185 for episode no. 598\n",
            "The episode no. is 598\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 2.6791\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 3.8237\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 1.5599\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.5816\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 2.1059\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 60.9009\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 1.9082\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.5362\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 63.4191\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 2.3138\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 2.1911\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 2.1841\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 2.5566\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 2.7879\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 2.2588\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.5631\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 2.6964\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 2.6283\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 3.0078\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 4.1020\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 2.2990\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 62.1116\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 2.4649\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 1.5765\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 3.1710\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.5310\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 3.2036\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 3.8470\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 2.5801\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.8315\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 2.6738\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.4580\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 13.0468\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 2.7934\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 3.7740\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 5.9366\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 3.3231\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 62.3140\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 7.9461\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 1.6696\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 62.2356\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.8404\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.8480\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 2.3194\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.6113\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.4655\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 4.4782\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 5.2026\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 2.1226\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 1.1761\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.9676\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.6159\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.6481\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.4753\n",
            "cummulative reward is -81.23796720714367 for episode no. 599\n",
            "The episode no. is 599\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 4.3217\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 1.0867\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 2.4204\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 3.9582\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.7912\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 2.4660\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 2.1746\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.0621\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.1008\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 2.4221\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.4029\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.3952\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 4.8460\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 1.8035\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.9263\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.9621\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.7944\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.4340\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 4.4018\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 2.1070\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.2604\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.4404\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 5.8940\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.7021\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 1.0837\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.9610\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.6780\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.4967\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.3432\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 4.5314\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.8009\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.9496\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 5.9068\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.2433\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.9385\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.0504\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.3410\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.1335\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.0214\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.0152\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.7331\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 16.7096\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 2.2816\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 2.1371\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.2555\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.8893\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.8483\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 1.6615\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 4.5804\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 5.8626\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 2.6280\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.6420\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 6.1664\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 5.9407\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.2582\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.2448\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.9180\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 3.7474\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.4788\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.8996\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 2.5498\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 6.4172\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.2091\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 2.4537\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.6107\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 2.5647\n",
            "cummulative reward is -32.14968728038686 for episode no. 600\n",
            "The episode no. is 600\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 3.2170\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.6308\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 2.0823\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 2.8093\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.6310\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 1.3956\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 7.1535\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 3.4350\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 1.0790\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 2.2085\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 2.0572\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 2.0763\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 2.8829\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 18.6972\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.8876\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.4044\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.1618\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 2.7427\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.7397\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 3.2481\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 4.4557\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 2.3373\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.6887\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 4.1080\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 4.8563\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 2.6787\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 2.1506\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.3515\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 4.4140\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.5429\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.0377\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.9050\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.4663\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 2.0714\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 3.0908\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.5055\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.1133\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 4.2095\n",
            "cummulative reward is -2.9012739632254014 for episode no. 601\n",
            "The episode no. is 601\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 2.7044\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.6242\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 9.5197\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 1.5000\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 4.5358\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 19.7616\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.8641\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 2.0522\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.1956\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.5082\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 4.1508\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.2740\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 2.6760\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 5.5063\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.8798\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 2.6946\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.3261\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 2.1392\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 2.7048\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.9785\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 1.4110\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.3788\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.7352\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 3.9844\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 3.7775\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 4.7754\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.7274\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.2416\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 2.2816\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 3.4166\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.4069\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 2.1945\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 2.5161\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.4429\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.1252\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.3556\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.9550\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 4.2358\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 6.3623\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 1.2725\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 1.4791\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 21.4642\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 1.2146\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 2.4899\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.0949\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 2.3098\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.8122\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.8215\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.1242\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.6174\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.0618\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 3.4100\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 2.8318\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.5036\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 5.7627\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 1.0342\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.4762\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.0144\n",
            "cummulative reward is 17.86962034334665 for episode no. 602\n",
            "The episode no. is 602\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.8688\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 1.5061\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.8847\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.8204\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 2.7181\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 2.4035\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 2.7874\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.7069\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.7980\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.4144\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 9.3455\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.9564\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.0588\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.9891\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.8324\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.3716\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 5.1813\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 3.7550\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 6.2221\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.3659\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.0869\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 6.2950\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.9803\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.4582\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 5.5114\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.5905\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 3.3346\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.9942\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.3237\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 75.8705\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.9798\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.6383\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 2.6460\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 1.6500\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 3.4786\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 1.4439\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.3695\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.0188\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 2.4631\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 3.0893\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.4869\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 2.1537\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 5.6988\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 6.6350\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 1.3885\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 3.3774\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 3.0814\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 6.4211\n",
            "cummulative reward is 12.555630534617883 for episode no. 603\n",
            "The episode no. is 603\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 16.0838\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.2007\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.0512\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.2362\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 1.7951\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.9611\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.8686\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 1.5699\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 1.8573\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.4271\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.3561\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.8509\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 2.5322\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.9900\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 1.9679\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 2.5225\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.3708\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 6.0814\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.8379\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 2.7891\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 2.4795\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.4370\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 4.4957\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.6497\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.6876\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 2.8730\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.7454\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.8782\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 1.5996\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 2.7893\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 6.4566\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.4757\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.2616\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 3.8450\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.2286\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 2.3132\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.0861\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 1.4752\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.9309\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 2.6976\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.9050\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 2.9729\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 3.5906\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.1843\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 1.7552\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.8484\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 33.5213\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.2050\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.7468\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 2.3889\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 2.0024\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 1.9994\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.6590\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.2371\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 3.2334\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.9484\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 2.0359\n",
            "cummulative reward is -28.765204895003244 for episode no. 604\n",
            "The episode no. is 604\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 3.3725\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.4820\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 3.5808\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.0602\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 1.0351\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 2.7167\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 7.0757\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6468\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 2.8701\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.6882\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.9945\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.3114\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.7954\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.3127\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.6979\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.7070\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 5.3826\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.5479\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 2.4113\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.6693\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 16.8326\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.7382\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.4927\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 2.7686\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.1392\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.5600\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 2.3287\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 2.1426\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 2.3347\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.3871\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 2.2237\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 1.7246\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 2.0236\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 1.2037\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.8463\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.6308\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.9147\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.8895\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 4.7197\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 2.2679\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.9790\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.8287\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 2.0184\n",
            "cummulative reward is -48.36944933807675 for episode no. 605\n",
            "The episode no. is 605\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 1.1886\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.5447\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.3341\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 40.9180\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.0243\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 2.0886\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.8627\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.5928\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.4084\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.2939\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.8369\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.8697\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 2.5555\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.4440\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.3528\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.7997\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.9017\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.3040\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 2.5321\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 3.3875\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.4508\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 3.1631\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.5406\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 27.6908\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.1002\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.6451\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 3.1185\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.8760\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 2.8143\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 1.9044\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.4061\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 9.7983\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.8305\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.9079\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 1.4241\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 4.3534\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.8890\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 2.5917\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.7757\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 5.4021\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 2.7501\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 2.5600\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.8722\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 3.1515\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 44.0727\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 2.6906\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.7248\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.1303\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 3.9154\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 3.2503\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.5919\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.5989\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.0503\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 2.0915\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.3731\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.9174\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 2.0383\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.9355\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.1516\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 1.1636\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 1.6465\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 2.0886\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 2.0421\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 87.0383\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.5179\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 1.9314\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.4403\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 2.6631\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.0097\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 2.9639\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 2.9394\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.4611\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.7559\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 4.4999\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 2.0058\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.4607\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.8845\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 2.4144\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 3.1852\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.5046\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.1443\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 2.6745\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.8688\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.8412\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 5.7217\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.2442\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 2.3923\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 2.1370\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 4.5845\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 4.6097\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 2.7123\n",
            "cummulative reward is 31.656680497812868 for episode no. 606\n",
            "The episode no. is 606\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 4.1941\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.0000\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 2.5964\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 3.2964\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 2.0744\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.5279\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.5355\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 2.2076\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 2.6393\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 4.7741\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 4.2860\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.7814\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.8828\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 3.5953\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.7741\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.9103\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.3477\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 1.9776\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 2.4121\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 3.7441\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.6025\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 1.2183\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 2.9403\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 2.3077\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 8.2807\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.4649\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 3.9777\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 2.3208\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 5.9221\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 2.5979\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.2854\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 3.3706\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 2.9695\n",
            "cummulative reward is -27.050189201476204 for episode no. 607\n",
            "The episode no. is 607\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.7637\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 43.2276\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 2.5906\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 3.5065\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 2.1516\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 8.0578\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 4.4743\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.9922\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 9.5250\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 2.9577\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 1.5840\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 2.0354\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 2.8724\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 3.6146\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 3.5535\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 5.2261\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.6618\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 3.8007\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 3.3348\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 2.4794\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 4.9127\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 2.1299\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.7739\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.9089\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.9678\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.4764\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 2.1884\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 3.1222\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 3.7134\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 1.9997\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 2.9943\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.1874\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 5.1852\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 2.4614\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.7623\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 2.6575\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 7.5851\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 2.2166\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 1.4598\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.2258\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 3.1699\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.4852\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 2.4273\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 2.1402\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 6.4269\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.9032\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 1.4373\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 2.4699\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.2397\n",
            "cummulative reward is -0.5953946862304491 for episode no. 608\n",
            "The episode no. is 608\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 3.1294\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.8282\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.4259\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 12.6850\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 2.1204\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.5179\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.5582\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 3.6871\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 1.4112\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 2.5505\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.7497\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.5232\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.8153\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 29.6465\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.5496\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 1.1605\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 2.0207\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 3.3751\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.0834\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 1.4312\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 2.5342\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 2.2338\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 2.9666\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 4.0763\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.5855\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.2744\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 2.8387\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 3.2576\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 2.1155\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.9129\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 2.0217\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.9989\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 2.6081\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.0873\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 4.3448\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 2.5976\n",
            "cummulative reward is -28.40197357171559 for episode no. 609\n",
            "The episode no. is 609\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 2.1648\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 3.2923\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 7.7070\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 2.4165\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.3883\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 2.8525\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 1.3853\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.2634\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.7163\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 1.7689\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.5028\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 4.0011\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.2390\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 1.2079\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 2.3345\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.8095\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 1.7613\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 3.6474\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 19.1763\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 2.1444\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 3.0618\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 3.1298\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.5748\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 9.6292\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 5.6284\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.4360\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 5.2336\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 2.2217\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 2.1951\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 2.0101\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 4.6406\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.2640\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 3.7492\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.6713\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.5054\n",
            "cummulative reward is 21.493224431212973 for episode no. 610\n",
            "The episode no. is 610\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.0220\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.7536\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 3.8384\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.5568\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 3.4180\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 2.6775\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 3.0614\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 2.2374\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 4.1512\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 2.6763\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.5422\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 2.9392\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.3572\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 2.1727\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 2.1363\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 1.7827\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.8532\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 2.5929\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 2.0055\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 3.1314\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.1713\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 2.0257\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.7359\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.5775\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.6305\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 3.0825\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.1556\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.5913\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 2.1980\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.4172\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 6.2780\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.7697\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 2.3121\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 2.1027\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.4132\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.1975\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.5888\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 3.3539\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.8822\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.5809\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 2.9735\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 2.2663\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.1455\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.6133\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.1356\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.1143\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 1.2872\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.9367\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.8773\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 2.3690\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 2.8863\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 6.0550\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 2.2052\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.3260\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.0118\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 2.7183\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.9957\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 2.2282\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 2.0442\n",
            "cummulative reward is 3.4468102910331107 for episode no. 611\n",
            "The episode no. is 611\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.4096\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 1.3405\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 2.7454\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 2.1477\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 2.2928\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.8987\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 2.4787\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.9512\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 5.7038\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.1649\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.9399\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 2.6726\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 4.8667\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.7471\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.4234\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 1.3613\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.6520\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 2.8977\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 2.2854\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 3.6552\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.7650\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 4.8518\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.2239\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 1.8963\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 1.5895\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 2.7868\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 3.0060\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 2.5364\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 2.7881\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.7131\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 22.2604\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.7938\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 3.7516\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.1493\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 47.3261\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 3.1814\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 4.9875\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 2.0834\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 1.2099\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 5.1495\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 2.1519\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 5.3107\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 3.9449\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 1.0992\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.6315\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 3.0932\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.6801\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 2.1188\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 4.4210\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 3.9127\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.9198\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.6647\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.5647\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 2.5385\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.7549\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.3359\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.5655\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 71.8726\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6675\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 2.8854\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 1.1490\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 2.8031\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 2.3243\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 2.8471\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 4.5587\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 1.0458\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 5.8232\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 1.9564\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 2.2889\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.0435\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.7724\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 2.4738\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 5.3809\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.2191\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.0485\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 2.2489\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 2.2566\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 3.7111\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 2.0297\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 2.1376\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 5.5428\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 4.8635\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.6409\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 7.2863\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.8864\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.8286\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 2.8360\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.7965\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 3.6610\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.8529\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 1.1392\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 2.3206\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.2518\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 3.9302\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 4.0079\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 2.5678\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 2.4050\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 2.8356\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 2.3553\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.0636\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 2.7880\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.0035\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 2.1827\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 2.2319\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.7208\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 2.0735\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.7561\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 2.6672\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.1090\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.9357\n",
            "cummulative reward is 0.11111340303608225 for episode no. 612\n",
            "The episode no. is 612\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.9739\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.7805\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 3.9649\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.2010\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.8562\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 11.2861\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 2.5168\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 2.5701\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 2.5615\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 3.7871\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 5.4886\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.6083\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6451\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.5420\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 3.6385\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.5626\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.4054\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 3.0632\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.5512\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.9603\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.7771\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.7257\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 2.0164\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.8208\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 2.0747\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.3698\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 2.6591\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 4.0914\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.9278\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 4.9070\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.7541\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 3.0811\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 3.5225\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.7750\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 2.7147\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 2.4083\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 3.4865\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 6.0741\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.9416\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.2707\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.7533\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 6.1475\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.8859\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.8075\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.7465\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 1.5517\n",
            "cummulative reward is -27.08741669710309 for episode no. 613\n",
            "The episode no. is 613\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 1.3092\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 1.7803\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.6308\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 2.2366\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.2137\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 1.5659\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.4445\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.5874\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.7091\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 1.2459\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 2.2571\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 2.3408\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.8679\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 1.5252\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 1.5071\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 2.5504\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.5819\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 2.0950\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.2107\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.2955\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 3.1637\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.1140\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 5.7189\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 21.5357\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.5869\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 2.1791\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 2.9339\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.6067\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 2.2674\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.4955\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 1.0773\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 1.8229\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 3.1324\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.1569\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.4919\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 1.2073\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 2.5169\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.7920\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 1.0619\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 3.6182\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.9824\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.8112\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.8330\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 2.6270\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 2.2803\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.4648\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 2.2376\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.4208\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 1.1617\n",
            "cummulative reward is 33.956991316421046 for episode no. 614\n",
            "The episode no. is 614\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 7.7754\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 10.6438\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.4164\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.7345\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 2.0592\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.4129\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 4.6039\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.0294\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.9184\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.9425\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.8718\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.5439\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.8020\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.7967\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.4265\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.6734\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.8863\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 2.4571\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.6966\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 1.7540\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.4706\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.3486\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.8254\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 13.9292\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.0272\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 2.6273\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 3.4743\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 1.2388\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.2262\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 26.9766\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.8655\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.2402\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 1.6000\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 2.3534\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.0319\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.8222\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 2.8540\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.4458\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 2.4609\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 3.0397\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 1.5697\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 3.3118\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 1.3120\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6068\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 5.0864\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 2.8491\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 7.5571\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.9895\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.5275\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.8642\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 2.3873\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 4.4279\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.7699\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 2.8044\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.0525\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 2.5585\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 3.5578\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.7292\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.9203\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.8882\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 9.9129\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6066\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.2699\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 2.0776\n",
            "cummulative reward is -1.2283942679496316 for episode no. 615\n",
            "The episode no. is 615\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.8774\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 2.4715\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 3.0577\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.4866\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.3817\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 1.5130\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.0656\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.6112\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 2.5432\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 4.7333\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 2.0587\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.7841\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.4134\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.8094\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 1.0388\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.5090\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.6537\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.8422\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 3.3571\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 4.6222\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.6750\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.7455\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.6026\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 7.6790\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.2279\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.7506\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.2975\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.7282\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 1.7801\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.9446\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6306\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 2.6422\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.1344\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.1897\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 5.3074\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.7356\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.8895\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 5.5971\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 3.6648\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 3.6927\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.9398\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.2979\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.8564\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 3.0365\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.9950\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 2.3643\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.3581\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.0387\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.0117\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 3.8415\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 3.0866\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 2.0692\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 3.7357\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 3.8739\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 1.3918\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 2.5685\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 2.3205\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 3.0167\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.3172\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 1.7211\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 2.0046\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 2.9935\n",
            "cummulative reward is -1.250595627728965 for episode no. 616\n",
            "The episode no. is 616\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 4.8442\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.4924\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 1.8387\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.7238\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.7912\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 2.8718\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 3.1722\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.0365\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.8040\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.8123\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.8411\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 3.3257\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.7997\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.7879\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 24.8944\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.9799\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 1.8107\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.9060\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 2.0515\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 2.2409\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 2.1195\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.7905\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 1.4133\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 1.4434\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 3.3412\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 34.8361\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 2.3655\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.9195\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 3.1393\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.1735\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 2.6526\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.7738\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 1.2807\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 2.4644\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 2.0961\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.6142\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 3.6578\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.5970\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.7656\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 3.2734\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 3.8676\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.0544\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 4.7974\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 3.9898\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.7499\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 1.4721\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 4.3142\n",
            "cummulative reward is -18.88637186556636 for episode no. 617\n",
            "The episode no. is 617\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.8313\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 5.0177\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 3.9407\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.9343\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 3.0305\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 1.3282\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 1.0781\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 3.0400\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 1.5961\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 1.1233\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 1.7425\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.1139\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 6.6764\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 1.3430\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 6.1173\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 2.1205\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 3.4301\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 2.0748\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 2.0664\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 2.0600\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 1.8888\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.6928\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 1.7415\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 2.3696\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 2.6755\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 4.8103\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 29.1054\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 2.3209\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 3.1235\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.8988\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 4.3962\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.8242\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 4.2282\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.4441\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 2.0320\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.7069\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 6.5598\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 1.9580\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 2.3395\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.4794\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 2.2849\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 1.5919\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 25.8140\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 4.0521\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 1.6182\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.9535\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.1965\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 6.1926\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 2.0452\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 11.1194\n",
            "cummulative reward is 9.368705677760477 for episode no. 618\n",
            "The episode no. is 618\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 1.4633\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.1784\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.0330\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 2.0764\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 2.0056\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.7082\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 2.2279\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 2.2359\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.8580\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 14.9892\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 3.8472\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 3.7807\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 4.3260\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 3.0433\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.5698\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 2.2346\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 2.7804\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 2.2698\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 2.6323\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 2.8257\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.1113\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.8383\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 2.3085\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.3186\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.8931\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 3.4764\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.0033\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.6100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.0570\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.7719\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.9238\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 1.9080\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.4952\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.3875\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 12.5685\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.0400\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.8036\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 3.1851\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.2967\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 6.8336\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 2.6501\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.1506\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 4.6222\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.8765\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 4.5068\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 2.4330\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 3.7450\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 2.8829\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.8547\n",
            "cummulative reward is -18.55169627326712 for episode no. 619\n",
            "The episode no. is 619\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.9127\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 1.5980\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.5234\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 3.6142\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 16.4835\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 3.9269\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.5569\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.5726\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 3.6330\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.7134\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 1.7974\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 3.1520\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 3.5263\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.4639\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 3.4217\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 9.5632\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 2.6051\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 3.8720\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 8.7738\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 2.3941\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 2.4357\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 1.2045\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 2.1215\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 7.5974\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 2.3109\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 2.0035\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 7.3081\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 2.4626\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.5621\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 4.0024\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.5934\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 2.8974\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 7.1071\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 9.5279\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 1.5636\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 2.7222\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 3.3232\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 3.5405\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 2.2858\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 9.2897\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 3.0861\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 3.0730\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 2.8243\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 2.8726\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.7035\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 4.1953\n",
            "cummulative reward is -38.884128122763045 for episode no. 620\n",
            "The episode no. is 620\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 7.8762\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 3.4645\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 2.0836\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 2.0517\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 2.2389\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 9.3695\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 3.4434\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 3.4001\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 2.6985\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 2.6572\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 2.9863\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 3.1360\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 3.7711\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 2.1213\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 3.7177\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 3.3940\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 2.5451\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 2.7007\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.9485\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 3.1744\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.7157\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 1.9831\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.2446\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.4662\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 2.2506\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 1.3841\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 9.1214\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.6462\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 2.8667\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 2.6442\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.0715\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.0292\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 2.1376\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 4.7150\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 3.5929\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 2.6415\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 2.9567\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 4.6927\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 4.2847\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.6633\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.6755\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 1.2945\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.8835\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.6734\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 3.1022\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.0284\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.9832\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 3.1760\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 2.2679\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.8552\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 3.4361\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 4.2523\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 3.0624\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 2.6055\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.4560\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.9131\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 2.2492\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.0266\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.8250\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 7.1741\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 3.0859\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.1516\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 3.4863\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 7.8658\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.8468\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 2.6658\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 3.6047\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 4.4612\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 2.9249\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 2.8267\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.0243\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 3.5391\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 5.3725\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 3.9173\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.8329\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 2.8936\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 8.5865\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 6.1041\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 1.1147\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 15.5789\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 1.6883\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 10.3298\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 1.6171\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 4.2040\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 3.3648\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.9997\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 8.0068\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 6.4924\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 7.2695\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 7.2523\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 1.9260\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.5843\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 7.2074\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 7.1673\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 4.2441\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 3.1513\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 10.8766\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 5.9403\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.8738\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.7788\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 11.4132\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 1.0762\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 5.0431\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 2.3672\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.2980\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.0313\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 2.9338\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 1.9809\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 2.4748\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 9.5361\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 7.6013\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 3.5488\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 1.1533\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.2149\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.7307\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.9094\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 5.7333\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 9.8337\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 12.5313\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 3.5465\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 2.7455\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 2.9706\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 3.0611\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 7.0052\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 2.4025\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 7.4731\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.9163\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 1.6505\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 2.0187\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 9.5779\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 3.7188\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 2.4445\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 1.8040\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 2.7113\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 4.3141\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 5.6533\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 2.4080\n",
            "cummulative reward is -53.142960206044975 for episode no. 621\n",
            "The episode no. is 621\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 2.0055\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 2.2862\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 3.5312\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 4.0736\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 2.3385\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 4.2352\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 3.5036\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.8229\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 2.9153\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 2.6399\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 2.5535\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 5.1669\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 3.1154\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 2.5674\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 2.7293\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.3287\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.3724\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 3.2026\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 2.8421\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 4.7374\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 2.9749\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 3.1792\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 3.1821\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 2.2736\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 94.0037\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 148.3809\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.7213\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 10.6202\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 7.7334\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 3.9264\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 5.7975\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 3.7649\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 4.7311\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 5.2770\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.3506\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 5.9106\n",
            "cummulative reward is -51.19691633144248 for episode no. 622\n",
            "The episode no. is 622\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 7.3676\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 5.7013\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 2.4734\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 5.9586\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 7.3922\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 2.1778\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 9.5216\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 2.3305\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 3.0693\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 2.9062\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 4.9135\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 2.3082\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 3.1814\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.6722\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 7.8980\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 5.1316\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 4.4405\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.7186\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 2.8498\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 1.3990\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 1.9506\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.3007\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 2.5053\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.2588\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.5934\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.9566\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 4.1244\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 4.0814\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 9.6453\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 6.0901\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 1.5497\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 7.5695\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 9.7956\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.9793\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 2.1276\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 13.0548\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 10.5304\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 5.8094\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 1.4199\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 2.6907\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 3.4149\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 2.5658\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 3.3236\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 4.2852\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.5132\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.6472\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 8.2225\n",
            "cummulative reward is -35.428836359036325 for episode no. 623\n",
            "The episode no. is 623\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 4.0751\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 1.5821\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 3.8954\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 2.8007\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 2.2386\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 5.6446\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 5.0222\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 2.3012\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 52.5593\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 4.4411\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 2.5354\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 3.7015\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.5302\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.1351\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 4.7888\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 1.4344\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 4.9413\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 2.7737\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 3.7325\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 4.1799\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 5.4440\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 1.5945\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.0321\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.6410\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 4.5134\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 2.0805\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 1.5052\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 1.6583\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.0921\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 3.8974\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 2.8228\n",
            "cummulative reward is -31.592267654828717 for episode no. 624\n",
            "The episode no. is 624\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 4.4924\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 3.1292\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 3.2198\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 4.2461\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 2.4285\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.8692\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 2.0013\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 4.0377\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 1.0322\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 4.0442\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 5.3404\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.5008\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 8.8569\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.1619\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 1.8183\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 565.4601\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 2.0130\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 4.0634\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 2.0540\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 13.1602\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 4.8225\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 8.4281\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.8515\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 10.8533\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 9.1240\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.3779\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 13.2664\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 3.8620\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 2.9665\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.7429\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.3598\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.4963\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 2.7657\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.4771\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 2.6310\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.5914\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 9.1520\n",
            "cummulative reward is -19.659691708630135 for episode no. 625\n",
            "The episode no. is 625\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.4294\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 2.0328\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.5249\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 1.4912\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 5.4544\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 3.6699\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 7.0721\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 6.5926\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 2.2193\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 2.8236\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.9349\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.6876\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 25.8207\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 3.9255\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 4.2256\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.6599\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 1.2492\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.8027\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 9.4050\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 10.2635\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.9903\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 1.7486\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 2.1159\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 2.1509\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 9.1549\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.3881\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 1.6906\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.1460\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.3129\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 1.9822\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 2.6959\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.1812\n",
            "cummulative reward is -44.73655308192038 for episode no. 626\n",
            "The episode no. is 626\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 1.6401\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 9.4531\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.0132\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 3.5631\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 1.6035\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 4.8293\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 10.5140\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 1.3312\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 3.3206\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 223.9870\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.5419\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 2.6717\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.3795\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 5.0755\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 7.3223\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 13.2771\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 9.3385\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 2.8114\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 2.0356\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 6.7950\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.6153\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 4.4115\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 4.8044\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 4.9361\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 3.9108\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 2.2688\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 3.5295\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 3.5155\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 1.4400\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 1.4313\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 1.9687\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.6856\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 1.6037\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.6082\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 1.4936\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 1.1114\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 11.6720\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 2.6640\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 6.6247\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.9462\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 1.7502\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 1.4727\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.7507\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.9719\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 2.8318\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 2.3149\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 3.2654\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 2.7028\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.0538\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 1.7075\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 2.1013\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 2.3656\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 1.3337\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.8464\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.2712\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.1941\n",
            "cummulative reward is -27.449689256316645 for episode no. 627\n",
            "The episode no. is 627\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 2.0809\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 2.6074\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.8035\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 3.3964\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.9907\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.5304\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 5.5857\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 2.1742\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.6417\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 6.5638\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.6445\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 2.1501\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 1.7285\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.9640\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 2.7108\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.7880\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.9868\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 1.6301\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 2.2770\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 5.9097\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 2.2105\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.8296\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.8627\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.3370\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.2403\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.5370\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.6521\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 2.0671\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 2.9252\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 3.1642\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.0464\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 2.8764\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 2.0995\n",
            "cummulative reward is -62.69838111251124 for episode no. 628\n",
            "The episode no. is 628\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 1.0827\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 2.5978\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 8.0386\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 1.6333\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.0172\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 4.1877\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 5.2999\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 7.7605\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 6.4885\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.9753\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.8372\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 2.1520\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 2.7375\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 3.0985\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.3961\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 1.3067\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 30.5502\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 232.8444\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 3.2473\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 2.5616\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 3.2133\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 5.1170\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 4.1674\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 5.6325\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.2612\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 2.4759\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.3213\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 3.2031\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 6.7690\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 6.7037\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 6.2546\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 2.9659\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 7.3659\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 2.3864\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 2.6003\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.1875\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 2.3026\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 1.4946\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 5.2850\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 6.9321\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.1478\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.9832\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 2.2784\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.2950\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.7083\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 1.3881\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.0437\n",
            "cummulative reward is 11.067406957677582 for episode no. 629\n",
            "The episode no. is 629\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 2.1963\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 1.2325\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.8230\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.7446\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 6.9875\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 6.1768\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.9104\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.8418\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 3.4818\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 3.3317\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.9182\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 3.4432\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.4769\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 7.6769\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 3.6137\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 2.6234\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 1.0021\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 3.0677\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.8475\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.9309\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.1751\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.5995\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 3.5976\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 3.3024\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 2.1443\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.4088\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.4072\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.9238\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 2.2682\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 2.1137\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 9.3502\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.1683\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 7.0035\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 1.7764\n",
            "cummulative reward is -6.816351371020065 for episode no. 630\n",
            "The episode no. is 630\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 12.2820\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 2.2813\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 2.3038\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 3.5302\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 5.3415\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.1542\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 6.3032\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.6577\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 5.2530\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.2891\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.8227\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.9383\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 2.0912\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 4.1650\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 5.4548\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 13.0140\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 1.2428\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 1.4112\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 3.8429\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 2.3014\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 2.2569\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 2.4761\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 10.2468\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 12.7022\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 7.0197\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 8.1217\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.9051\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 3.1838\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 4.5234\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 3.0214\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.9272\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 1.1011\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 2.9220\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.2688\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 1.7929\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 1.2674\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.8295\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 9.3534\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 16.2940\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 1.7247\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.9942\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 2.3054\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 8.7992\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.5903\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.5443\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.6908\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 7.9524\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.2380\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.2806\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 2.9731\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.6453\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 1.2129\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 1.5173\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 3.0520\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 5.8604\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.7815\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 2.0381\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 5.0265\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.0701\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.5199\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 6.9471\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 2.4311\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 3.9761\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.0947\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 6.1609\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.6869\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 2.8757\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 4.0976\n",
            "cummulative reward is -30.750376708036995 for episode no. 631\n",
            "The episode no. is 631\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 3.1980\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.8332\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6896\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 6.5032\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.7638\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 5.2824\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.5558\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 2.1015\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.9211\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 3.3771\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 1.4090\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 3.7716\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 2.1473\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 3.4736\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.6769\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 2.1952\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 2.7591\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 4.7413\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.5873\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.8968\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.4139\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 3.6737\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 2.2926\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 1.6325\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 3.0660\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.3712\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 6.7567\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 2.9942\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.7186\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.9963\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 2.9543\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 4.8880\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 3.3497\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 2.1823\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.7318\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 2.2501\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 2.4351\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 3.6524\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.2242\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.5284\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.8570\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 3.6761\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 2.4839\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 2.5569\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.9621\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.2853\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.2231\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.3369\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 3.9216\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 3.4688\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.9840\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.2745\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.5760\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.1072\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.9282\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.5552\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 6.6287\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 1.1601\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 2.4419\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 2.5495\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 3.0514\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 1.5248\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.9216\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 3.3882\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 1.0648\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 1.7383\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 2.0437\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 3.0482\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 3.0263\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.1938\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.7719\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.1810\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.6231\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 3.9649\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 1.1526\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.7686\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.8631\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.5516\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.3578\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.1962\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.3004\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.9650\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 6.2884\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 2.6817\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 2.9131\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.5864\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.3691\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 3.7137\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 2.5196\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.5226\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 1.2272\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 2.3261\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 2.5244\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.8130\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 2.6070\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6013\n",
            "cummulative reward is -13.602658644680798 for episode no. 632\n",
            "The episode no. is 632\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 2.4124\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.6432\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.9953\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.7663\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.9606\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.2992\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.2903\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.7160\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.6928\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.6255\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.5697\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 4.0793\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.2945\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 3.5501\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.5857\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.1884\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 1.1164\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 2.9052\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 1.3676\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.5447\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 3.7184\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6490\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.5040\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.5704\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.6463\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.5824\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.2488\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 2.5034\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.8437\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.7402\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 2.0260\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 3.3710\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 4.7266\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 2.0315\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.7209\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 2.4839\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.5283\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 2.4719\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 1.0658\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.5686\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 3.6703\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.3615\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.0913\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 3.1633\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.9660\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.9287\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.7990\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 1.2883\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 4.0640\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.1721\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 2.5172\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 7.4017\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6111\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 3.8658\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.5021\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 2.6240\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.5399\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 2.7444\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.7911\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 4.8459\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.7751\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.2340\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 3.0167\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.2329\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 2.7780\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 1.5551\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 2.5453\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.4074\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.0800\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.5765\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 2.8320\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 2.4281\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 2.7332\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 4.4084\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 3.2293\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.3373\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 2.5016\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 2.4115\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.6208\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 3.0068\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.0403\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 2.3375\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6209\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.6858\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.0821\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.9546\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 4.4175\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 2.9250\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.6916\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 2.1932\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.9952\n",
            "cummulative reward is -4.344530543071357 for episode no. 633\n",
            "The episode no. is 633\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.4904\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.3990\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 3.1520\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 1.2896\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 3.7515\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.7304\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.9615\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 1.6208\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 4.2160\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.6481\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 3.7767\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 3.9437\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 2.9193\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.1160\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 5.9340\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 2.4150\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.1476\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.3961\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 2.1962\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.9309\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 1.5755\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.8455\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 2.0503\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.9979\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 2.0879\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.2022\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.8897\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.3134\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.9189\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 2.0958\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 1.1127\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 1.0601\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.0329\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6090\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.9687\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.7588\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 2.8985\n",
            "cummulative reward is 27.75653667624431 for episode no. 634\n",
            "The episode no. is 634\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 2.2581\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.8382\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.2627\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.9852\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 2.3162\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.6606\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.9555\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 7.8569\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 6.1049\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 1.4285\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.7828\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 7.9240\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 2.3388\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.1245\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 2.2563\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 3.5909\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 1.6598\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 2.5553\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.2441\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.3592\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 4.9665\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.2340\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 3.3816\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.7267\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 2.1438\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 2.1181\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.9907\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.9163\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.4034\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 3.0107\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.7252\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.8904\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.4760\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 1.4562\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.7615\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 2.4231\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 1.0216\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.9498\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.9940\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.0187\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.8440\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.7579\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.3219\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 2.3340\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 1.5983\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 2.6565\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.9437\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.2131\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 2.8406\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.3791\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.5293\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6321\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.8167\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 1.3068\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 1.7416\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 2.3311\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 2.2733\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 10.6575\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.6642\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.4334\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.0361\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.9739\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.1257\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 2.1502\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 1.0051\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 3.3053\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.8316\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 2.1226\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.9977\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 1.9079\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 1.5975\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.1553\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 5.5637\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 4.4141\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 1.2467\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.5287\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.3554\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 1.6107\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.9885\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 2.6353\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.0969\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.7572\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.9465\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 3.7476\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 3.1944\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 5.2576\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.2016\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 5.0247\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.5124\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.6449\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 1.6410\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6976\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 2.4035\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.7488\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.8323\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 5.1906\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.8252\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 1.5691\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.6968\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.4357\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.5646\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 5.5452\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.2429\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 2.2592\n",
            "cummulative reward is 9.236412797989878 for episode no. 635\n",
            "The episode no. is 635\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.1129\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 3.2922\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.8238\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.1327\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 2.0069\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.9558\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.3558\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.8536\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.0249\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 3.1102\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.4366\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.1290\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 2.1643\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.8889\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 3.5697\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.7324\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 2.9450\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.9324\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 3.3673\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.9327\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.8245\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 2.0230\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 1.4937\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 2.4556\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.8749\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 2.0332\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 1.9365\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.6603\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.0095\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.2496\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 3.7278\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.9720\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 1.8555\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.0196\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 3.1510\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 2.9365\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.6720\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6561\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.9262\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.5218\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 2.4617\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 5.2055\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 2.7093\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.1252\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 1.5641\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 4.5595\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 2.7904\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.8832\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 4.7874\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.0839\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.2232\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 1.7710\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.0121\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.4318\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.9096\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 1.1831\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 14.3175\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.0040\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 2.0562\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 2.9636\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.4823\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.8872\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.1868\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 1.8977\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 2.9535\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 2.4220\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 2.4519\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.6474\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 2.3182\n",
            "cummulative reward is -28.286651302852526 for episode no. 636\n",
            "The episode no. is 636\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 5.7525\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.5537\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.1351\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 2.5904\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.8380\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 3.4123\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 2.0395\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.5375\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 2.3869\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 4.2754\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.7695\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 1.5764\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 2.0588\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.3392\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 4.2915\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 3.3994\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 1.4264\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 3.0203\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.9818\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 3.3441\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 3.1324\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 1.0043\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 1.0570\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 2.4672\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 2.4784\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.0036\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 2.1862\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.3486\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 2.4670\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.6583\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.6127\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 1.0377\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.9323\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.5953\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.9353\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 3.9581\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.5068\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 1.0042\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.7899\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.9968\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.3475\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 2.1573\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 1.8852\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 1.0780\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.6243\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 1.4361\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 117.0337\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 3.6116\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.3609\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.2296\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 1.5372\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.3034\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 2.1612\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 1.6180\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 3.5454\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 3.6502\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 3.2707\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 4.1211\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 2.3547\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.0224\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 3.1897\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 2.1677\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 1.4590\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.8074\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 4.4132\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 2.4209\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 2.4233\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.0635\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.7993\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.1072\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6857\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.6885\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.9775\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.9805\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.0558\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.8857\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.7513\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.9535\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.8070\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.1221\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 1.9408\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 2.3961\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 2.9373\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 4.0673\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.8205\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 2.8182\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 1.2775\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.0914\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.7139\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 2.0155\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.7384\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 2.0969\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 1.3009\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.3656\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.3479\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 3.7766\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.8235\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.5432\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.8587\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.1479\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.6273\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 3.7905\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 4.4709\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.7206\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.7581\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.9642\n",
            "cummulative reward is -30.113683513476015 for episode no. 637\n",
            "The episode no. is 637\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.8733\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 1.3297\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.5281\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.7281\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.0787\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.7093\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.8498\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.2263\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.7210\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 2.6928\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.4494\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 1.5086\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 2.1211\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 2.9375\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6831\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.8787\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.5280\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.1611\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 3.7979\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 2.5218\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 2.7350\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 2.3843\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6688\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 3.3299\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.8920\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 2.0965\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 1.2229\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 1.0977\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.0328\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 5.2183\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.0600\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 5.1385\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 2.2063\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 1.6915\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.8827\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 1.5850\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.7746\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.8896\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.0703\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.8129\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.9875\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 3.4331\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 2.1525\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.5798\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 2.5552\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.9340\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.4220\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.4665\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.9269\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.9909\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.8296\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.8040\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 1.4115\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.8061\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 2.2947\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.9362\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.2446\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 6.2141\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 3.2641\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.3727\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.6280\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.6225\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.9468\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 135.3514\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.8999\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.7155\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 2.6153\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.0897\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.9415\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 1.2405\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.8101\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 3.0720\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.9002\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.9424\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 2.2576\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 3.6984\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.2258\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 2.2476\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.5176\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.9412\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 2.4832\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.6043\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.9927\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.8017\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.6462\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.1416\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 4.8384\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 1.4199\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 4.9953\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 2.6471\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.9264\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.5551\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.7280\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 3.4056\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.2669\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.0542\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.6939\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.2289\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.5211\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 1.3689\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.7439\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 2.3294\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.6078\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 1.0732\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.2640\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.6777\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.6081\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.0967\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 1.8043\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.7339\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.1778\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 1.1638\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.1035\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.5573\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.1531\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.7020\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.7856\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 2.5796\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 1.5040\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.7972\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.9900\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 1.2051\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.8770\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.0649\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.0423\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 4.1833\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.0064\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 1.9573\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 1.3701\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.9962\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 2.0040\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.7851\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 2.5585\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.5616\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.7716\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.3429\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 2.5425\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 1.3866\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.9941\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.6944\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.9898\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.9678\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 3.1359\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.1935\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 2.3730\n",
            "cummulative reward is -19.069635497739117 for episode no. 638\n",
            "The episode no. is 638\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.8911\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.5062\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 1.5053\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.9991\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 3.4861\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 1.0128\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.9909\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.4700\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 9.5220\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 1.1288\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.9439\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.8546\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 2.4131\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 1.9182\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.9740\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 2.7075\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 3.7266\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.1369\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.8908\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.8902\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 3.2995\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 1.2989\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.7042\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 1.0544\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.2456\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 2.0283\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.5928\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6571\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 1.6532\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.8565\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 1.1367\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.6872\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.2329\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 1.7362\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.8480\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.0978\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.9204\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.7736\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.8645\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 1.2922\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.7659\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.6000\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 6.4432\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.6295\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 2.2567\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 1.1190\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.9024\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 2.2001\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.6304\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 5.8708\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 2.7177\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6721\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.9756\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.8426\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.9848\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.9510\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.0203\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 2.0931\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 1.4044\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 3.4093\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.2862\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.0268\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.1849\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.9275\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.9261\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.3374\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.9459\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 2.9487\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.1266\n",
            "cummulative reward is -33.52284037967822 for episode no. 639\n",
            "The episode no. is 639\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.9164\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.2721\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.7085\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.7992\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.9005\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.8635\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 97.0232\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.7758\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.1219\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.6724\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.6320\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.8883\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.8975\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.9215\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 2.7984\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.7465\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 3.3795\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 4.9558\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 2.3459\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 2.4159\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 2.6558\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 9.5942\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.9142\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.9227\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.2838\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.8186\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.1478\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 1.5327\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.5884\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.7743\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.9826\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.7801\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.8737\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 1.0193\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.8582\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.9349\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 1.2267\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 1.0339\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 3.5941\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 2.8632\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 1.3585\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 2.3498\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 1.3478\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.1168\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 1.1821\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.2058\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.9467\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 2.2586\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.4538\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 3.3202\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.2305\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 4.9104\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 1.5776\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 2.3447\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.8287\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 4.6805\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.8675\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 4.1416\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.9355\n",
            "cummulative reward is 6.742019512444534 for episode no. 640\n",
            "The episode no. is 640\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 61.7060\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 6.6951\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 62.8206\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.2702\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 1.6074\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.7568\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 2.5320\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 4.5593\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 3.2773\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 1.9224\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.3778\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 1.8863\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 1.2784\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 5.6695\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 2.3992\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 2.7411\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 1.2626\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 5.4841\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 2.5558\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.0196\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.6720\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.8520\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.3299\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 3.3285\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.2014\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 17.4245\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 62.1658\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.7978\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 28.6930\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 1.4817\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 2.3794\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 4.3657\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.0476\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 1.7419\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 2.1309\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 1.8975\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 1.5467\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.6978\n",
            "cummulative reward is 12.765895577235533 for episode no. 641\n",
            "The episode no. is 641\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 5.9449\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 1.3377\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 8.5205\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.2071\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 1.1933\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.6815\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.9497\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.0493\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.6896\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 1.3805\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.5703\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 17.0612\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.8645\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.3238\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.0498\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 2.8467\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 1.4984\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 62.1634\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 12.4875\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.3451\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.4562\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 2.0238\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 4.2488\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 2.1791\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.7524\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 1.0895\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 13.6333\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 1.8045\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.0431\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.1818\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.5585\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.9688\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 3.4007\n",
            "cummulative reward is -157.50229010555492 for episode no. 642\n",
            "The episode no. is 642\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 8.4148\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.5545\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 60.0326\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 16.0045\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 59.7358\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 2.2007\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 2.3274\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.5022\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 5.7439\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 1.5864\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 2.0368\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 1.2356\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.5869\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 5.2763\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 4.6889\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 3.7627\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 2.6685\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.6459\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 3.9598\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 1.0469\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 3.6557\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 2.9103\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 2.1208\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 3.2445\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 2.8180\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 2.2677\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.2694\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 4.0488\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 2.0268\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.3357\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 3.0813\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.0044\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 65.5629\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 2.6363\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 1.7845\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 2.0281\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 4.1536\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 1.4686\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 1.8686\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 2.1674\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.7679\n",
            "cummulative reward is -50.38817956726184 for episode no. 643\n",
            "The episode no. is 643\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 66.1428\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 63.0744\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.8376\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.3784\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 2.1547\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 3.3100\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 4.2216\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 7.2143\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.4215\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 60.1352\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 1.1192\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 1.3641\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 1.2277\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 2.4025\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 58.7695\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.8659\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 9.8639\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 4.6904\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 57.4352\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 3.8064\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 2.5154\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.9540\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.3235\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 3.2740\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 3.6128\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.2324\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.5299\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 2.4169\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.8910\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 111.8044\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.3063\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.5735\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 1.0367\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 2.5797\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 3.2610\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 7.8395\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 2.9033\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 2.5040\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 11.8620\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.5737\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 4.2794\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.6158\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 1.6406\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 3.5016\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 2.2711\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 2.0086\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 1.6795\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 3.2668\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.9443\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.8994\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 1.3184\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 1.0555\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 2.1414\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 2.2128\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.3639\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.3298\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 2.7109\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.8141\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 60.3467\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 4.0772\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 12.7707\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.5868\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.5361\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.6449\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.5601\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 3.7917\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 2.7495\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 12.0918\n",
            "cummulative reward is 7.516901961474023 for episode no. 644\n",
            "The episode no. is 644\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.9448\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 1.4691\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.7092\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 61.7455\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 5.9279\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.1323\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 2.0360\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 2.6137\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 11.4960\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 2.7988\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 1.3745\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 2.1410\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 2.7113\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 6.0774\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.0048\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.9038\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 2.5767\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.4859\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 3.9356\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 2.1107\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 2.0281\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.8419\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 59.7417\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.0661\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 3.6131\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.8089\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 1.6247\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.0490\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 20.5782\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 59.4322\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.7688\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.4702\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.1100\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.7256\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 2.2442\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.1749\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 2.3375\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.1100\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.8764\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.8421\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.9149\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.6786\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 3.3111\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 2.9586\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 2.1410\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 1.2991\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.7609\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 2.5091\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.9287\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.4315\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 1.3190\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 3.0342\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 1.6702\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 2.6302\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.7926\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 1.3459\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 1.8130\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.6957\n",
            "cummulative reward is -37.70131027815487 for episode no. 645\n",
            "The episode no. is 645\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 4.4554\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.3709\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 9.9844\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 12.2445\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.7345\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.6067\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 63.6286\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 7.0121\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.3013\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 62.0050\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.8420\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 2.9190\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 1.3151\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 61.7548\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.1892\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.3929\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 1.2104\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.5376\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 2.4652\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 2.1012\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 1.5829\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 161.0996\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 2.0059\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 1.1956\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 2.0947\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 2.9606\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 1.9809\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 2.7371\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 3.4533\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 60.6707\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 237.6949\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 7.3250\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 14.2486\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 60.7943\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 5.7731\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 10.9329\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 9.1985\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 83.3807\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.3874\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 5.7909\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 7.1820\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 9.7981\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 7.5849\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 10.2185\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.7093\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 4.9303\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 2.5048\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 2.7098\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 3.2140\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 33.7980\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 3.0307\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 5.0716\n",
            "cummulative reward is 8.69861610744053 for episode no. 646\n",
            "The episode no. is 646\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 6.1990\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 2.0706\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 4.3059\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 2.1725\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 1.7950\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.3604\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 3.3840\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.7015\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 2.8025\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 2.4745\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 8.4984\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 1.1825\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 21.8031\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 188.2416\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 1.0793\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 1.3478\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 2.3166\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 2.1360\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 1.7765\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 1.4086\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 3.8059\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 2.5628\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 1.0419\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.5484\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 4.0535\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 3.6632\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 3.8375\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 3.5313\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 2.5112\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 1.7508\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.4966\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.3217\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 1.3486\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.9647\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 2.2522\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.9704\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.6111\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.3631\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 5.8045\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 19.7677\n",
            "cummulative reward is -44.55258952959355 for episode no. 647\n",
            "The episode no. is 647\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 1.7445\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 1.6795\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 1.2250\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.3167\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.0341\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 2.7891\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.4236\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.5966\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.4120\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.7296\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 3.9023\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.8741\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 1.5146\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 1.1883\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.3959\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.9063\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 2.6204\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 1.6081\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.4979\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 4.0562\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 62.0642\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 8.0910\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 2.2707\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 9.5804\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.6890\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 0.5148\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.0709\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 1.1865\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 3.3576\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.8639\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 2.6874\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 2.3637\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 1.6539\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 1.1120\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 3.5580\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 63.6445\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 6.3691\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 63.6842\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.7021\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 2.8858\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 2.4072\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 2.9664\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 5.8130\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 1.6832\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 1.3271\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.4538\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 2.6700\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.1514\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.5823\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 2.0786\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 1.7452\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 3.4221\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 1.0973\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.5364\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.8204\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.2493\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 28.4057\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 3.2880\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.2847\n",
            "cummulative reward is -33.15104967222164 for episode no. 648\n",
            "The episode no. is 648\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 6.4724\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.1843\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.3518\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 4.8616\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 4.0356\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 4.2324\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 2.1855\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 1.9911\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.8828\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.6976\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.0589\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 2.2009\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.0794\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.9165\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 72.7884\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 2.2884\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.7841\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 3.1989\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.9203\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 1.6691\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6338\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 6.9695\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 4.4265\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 3.2635\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 2.2886\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.9461\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 3.5468\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 5.3756\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.1878\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 4.3381\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.0210\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.3544\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.0845\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 2.6789\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 9.1825\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.1063\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.2580\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 7.7765\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.4196\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 5.6353\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 2.1170\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 3.0946\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 2.5106\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.9431\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 1.3556\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 1.6608\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.0007\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.8493\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.1077\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 2.0466\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.8097\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 7.9448\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.1225\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.9761\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.9479\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.5721\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 2.1899\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 15.2954\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.0381\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.3382\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 2.9446\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.3081\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 2.0138\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.3987\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.7580\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 6.1965\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.9329\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.0352\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.7904\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 3.4114\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 1.8719\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 5.6564\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 3.0558\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 2.2181\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.8274\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.7458\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 1.4193\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 8.9720\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 3.0978\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 3.1412\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 3.8607\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 6.8598\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 2.5221\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.8691\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 1.7455\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 2.2646\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.0700\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 5.5133\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 1.4173\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 2.9445\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.7732\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.7678\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 2.7044\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 3.1514\n",
            "cummulative reward is 9.008969364766092 for episode no. 649\n",
            "The episode no. is 649\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 2.6313\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 6.6812\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 1.1847\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 3.3703\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.8186\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 2.3647\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.1348\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.0803\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 3.8264\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 2.0197\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 80.1090\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.2021\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 55.3663\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.8735\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 11.4952\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 3.1936\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 6.4929\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 1.8070\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 75.4120\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 6.1467\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 3.3834\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 5.4074\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 5.6750\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 8.5063\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.6007\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 1.6609\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 4.3707\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 1.8664\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 2.1147\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 2.3933\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 6.3670\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.3520\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 10.8073\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 1.6438\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 4.2745\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 2.4128\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.2498\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 3.1063\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 10.7571\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.7476\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 8.0329\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 4.4186\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 3.1053\n",
            "cummulative reward is -71.74849703872236 for episode no. 650\n",
            "The episode no. is 650\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.2709\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 2.1463\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 8.9364\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 61.8905\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 2.0582\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 3.6027\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 2.7953\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.4574\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 3.0407\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.2493\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.8003\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 2.1716\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.8801\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.4577\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 1.4114\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 2.7995\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 2.8255\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 17.9497\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 7.1942\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 9.7437\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.2672\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 4.1442\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 2.3141\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 4.0890\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.0588\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 1.3461\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 66.0845\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.9813\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 2.2321\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 3.4329\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 1.8471\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 2.0363\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.3441\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.9517\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 2.5290\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 63.1996\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 2.5870\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 2.7640\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.9129\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 2.5408\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 74.6179\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 1.1646\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 3.3072\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.8803\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.7164\n",
            "cummulative reward is -46.09492613644177 for episode no. 651\n",
            "The episode no. is 651\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 2.1835\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 3.7844\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.3459\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 31.6601\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 3.7410\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 2.5347\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.9682\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 1.7442\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 2.7551\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 2.8578\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 2.9101\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 12.1691\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 62.3372\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 19.5785\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 3.6157\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 74.7583\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.8558\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 4.3390\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 3.0858\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 3.1312\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 2.4333\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 8.5750\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 3.2295\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 2.9796\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 2.7890\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 2.3169\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 4.4626\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 3.0248\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.5146\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 8.2986\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 8.1111\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 1.1499\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 3.5978\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 7.1134\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.7827\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 65.6474\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.5484\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 21.1416\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 63.8659\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 2.5909\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 3.2023\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.6208\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 2.8909\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 1.1657\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 3.7920\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 2.0466\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.5091\n",
            "cummulative reward is -7.54919705215264 for episode no. 652\n",
            "The episode no. is 652\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 2.5043\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.7276\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 2.8125\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 2.6889\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 3.0387\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 2.1870\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.7146\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 4.3712\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 7.3355\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 6.9104\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 3.7198\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 1.4684\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.6718\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 2.1884\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 4.2761\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.4503\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 62.4704\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 3.6732\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 3.4622\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 26.3170\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 2.8214\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 7.2148\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 65.1574\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.8720\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 7.0058\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 3.4410\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 4.1284\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 2.2253\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.8188\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 4.3339\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 2.3176\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 67.5436\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 4.5591\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 5.7539\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 2.3210\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 4.1443\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 5.9023\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 4.6399\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 3.4394\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 2.0752\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 3.2908\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 1.4915\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.9397\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 6.3042\n",
            "cummulative reward is -21.960725607883575 for episode no. 653\n",
            "The episode no. is 653\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.4392\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 6.7371\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 3.9456\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 7.2385\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 1.0512\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 2.0331\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 4.1611\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 3.4732\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 64.0329\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 5.4994\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 1.0995\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 2.6813\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 1.4025\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 3.8858\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 3.2919\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 5.0613\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.8200\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 4.3773\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 2.4879\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.9333\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 62.2936\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 2.5081\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 2.2902\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 3.0712\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 3.4161\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 2.1116\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 2.1118\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 2.6646\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 2.0276\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 0.9819\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 61.5564\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 2.2478\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 2.8893\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 5.1967\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 2.4767\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.8691\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 12.8018\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.6061\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 2.6567\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 2.5992\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 62.7756\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 13.8210\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 64.8516\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 3.2176\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 12.4089\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 5.2496\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 2.8384\n",
            "cummulative reward is -42.87189038761658 for episode no. 654\n",
            "The episode no. is 654\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 2.8851\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 3.1442\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 4.7003\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.3469\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 2.6017\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 3.3916\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 2.4083\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 7.1185\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.2128\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 66.3999\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 8.3825\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 60.9130\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.5860\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.4568\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 3.6391\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 2.5491\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 2.0078\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 2.3296\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 60.6776\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.8118\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 3.1122\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 62.2274\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.7696\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 2.5502\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 1.9482\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 3.1300\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.7595\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 3.6955\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 2.4221\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 30.9782\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 1.5197\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 2.3021\n",
            "cummulative reward is -98.90156449402733 for episode no. 655\n",
            "The episode no. is 655\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 2.2605\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 53.9200\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.3933\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 1.9155\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.4091\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.7873\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 7.1436\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 1.9582\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 109.2458\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 2.1790\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.6800\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 1.6238\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 66.4007\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 3.5769\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 63.8566\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 6.8659\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 5.7485\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 5.5796\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 3.9427\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 9.3888\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 14.1489\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 3.6196\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 4.7850\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 5.1020\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 2.5063\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 1.8684\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.3079\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.4140\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 3.1047\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 4.0390\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 5.4297\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 3.8680\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.7360\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 2.6772\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.1601\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 3.7126\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.6902\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 4.5006\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.4608\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.6560\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 1.5946\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 2.4350\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 4.7000\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.7353\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 3.3097\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 942.5806\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 2.5696\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 2.4162\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 4.6918\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 4.8822\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 2.4741\n",
            "cummulative reward is -57.851543753231795 for episode no. 656\n",
            "The episode no. is 656\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 67.8696\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 18.4293\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 4.0230\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 4.0131\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 14.3343\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.3995\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 2.4171\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 2.7026\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 7.9592\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 2.4168\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 2.2039\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 1.9227\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 7.8499\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 8.1066\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 5.3316\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 6.4548\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 17.9139\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 4.5997\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.3209\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 5.5760\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 4.1028\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 61.8285\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.5773\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 60.9465\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 11.2577\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 2.3134\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.7885\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 23.6345\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.4081\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 2.9298\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 3.2727\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.8576\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 4.2480\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 3.9562\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 43.4562\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 2.0648\n",
            "cummulative reward is -15.713851974061143 for episode no. 657\n",
            "The episode no. is 657\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.7924\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 1.9923\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 8.9617\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 6.3580\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 6.5029\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 62.8203\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 2.2729\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 16.3842\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 12.4666\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 2.8816\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 6.1623\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 9.3140\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 62.7476\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 5.9330\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 2.6585\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.5359\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 3.2882\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 4.4175\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 4.5051\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 3.7127\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 8.5013\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 6.1933\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 2.6678\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 3.3744\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 2.3080\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 3.5383\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 1.1824\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 2.4330\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 2.9360\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 20.8035\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 4.5040\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 5.8664\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 6.3662\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 61.7517\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.6849\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 3.6267\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 1.6871\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 2.0193\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 4.6010\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 2.2450\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.7798\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 0.6714\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 2.6117\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 6.8272\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 1.0317\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 3.4288\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.2941\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 1.7815\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.0848\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 5.2738\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 0.8005\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.9337\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.4178\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 1.2809\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 2.9057\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 7.9218\n",
            "cummulative reward is -13.643853083378584 for episode no. 658\n",
            "The episode no. is 658\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 3.1954\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.4507\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 2.2440\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 2.8485\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.7325\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.4725\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.0293\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.9653\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 1.0484\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 0.8020\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.1735\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.4939\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 4.8853\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.0426\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 2.2724\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 2.6017\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 3.4316\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 1.0561\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 2.1101\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.1253\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 1.2165\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 6.8112\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 1.2953\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 0.6958\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 2.1856\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.4689\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.8245\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 0.7803\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 58.1413\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 4.2300\n",
            "1/1 [==============================] - 0s 4ms/step - loss: 1.9503\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.5944\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 1.3427\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 1.6592\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 4.8659\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.8957\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.4353\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 0.6262\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 1.2433\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 2.6173\n",
            "1/1 [==============================] - 0s 6ms/step - loss: 1.2177\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 2.3282\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 9.9752\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 2.8711\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 2.8977\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 5.9123\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 3.7155\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 3.3861\n",
            "1/1 [==============================] - 0s 5ms/step - loss: 3.3068\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-2f88f0e7882a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mddql\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepisodes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnumber_of_episodes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mgamma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.99\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malfa_lr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.001\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecay_factor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdecay_factor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-7-058d74be4ace>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, episodes, gamma, alfa_lr, decay_factor, replay_buffer_size, minibatch_size)\u001b[0m\n\u001b[1;32m     72\u001b[0m                     \u001b[0mmax_a\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnext_q\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m                     \u001b[0;31m#print(\"8\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m                     \u001b[0mdouble_q\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_target\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate_next\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mminibatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mobs_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m                     \u001b[0;31m#print(\"9\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m                     \u001b[0mtarget_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreward_\u001b[0m  \u001b[0;34m+\u001b[0m \u001b[0mgamma\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mdone_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgather\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdouble_q\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_a\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1959\u001b[0m           \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1960\u001b[0m           \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1961\u001b[0;31m           steps_per_execution=self._steps_per_execution)\n\u001b[0m\u001b[1;32m   1962\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1963\u001b[0m       \u001b[0;31m# Container that configures and calls `tf.keras.Callback`s.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36mget_data_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1397\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"model\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"_cluster_coordinator\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1398\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0m_ClusterCoordinatorDataHandler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1399\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mDataHandler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1400\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1401\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, x, y, sample_weight, batch_size, steps_per_epoch, initial_epoch, epochs, shuffle, class_weight, max_queue_size, workers, use_multiprocessing, model, steps_per_execution, distribute)\u001b[0m\n\u001b[1;32m   1159\u001b[0m         \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1160\u001b[0m         \u001b[0mdistribution_strategy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistribute\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_strategy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1161\u001b[0;31m         model=model)\n\u001b[0m\u001b[1;32m   1162\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1163\u001b[0m     \u001b[0mstrategy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistribute\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_strategy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, x, y, sample_weights, sample_weight_modes, batch_size, epochs, steps, shuffle, **kwargs)\u001b[0m\n\u001b[1;32m    324\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mflat_dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    325\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 326\u001b[0;31m     \u001b[0mindices_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindices_dataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflat_map\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mslice_batch_indices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    327\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    328\u001b[0m     \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mslice_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindices_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36mflat_map\u001b[0;34m(self, map_func, name)\u001b[0m\n\u001b[1;32m   2058\u001b[0m       \u001b[0mDataset\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mA\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mDataset\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2059\u001b[0m     \"\"\"\n\u001b[0;32m-> 2060\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mFlatMapDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2061\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2062\u001b[0m   def interleave(self,\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, input_dataset, map_func, name)\u001b[0m\n\u001b[1;32m   5278\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_input_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5279\u001b[0m     self._map_func = structured_function.StructuredFunctionWrapper(\n\u001b[0;32m-> 5280\u001b[0;31m         map_func, self._transformation_name(), dataset=input_dataset)\n\u001b[0m\u001b[1;32m   5281\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_map_func\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput_structure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDatasetSpec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5282\u001b[0m       raise TypeError(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/data/ops/structured_function.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, func, transformation_name, dataset, input_classes, input_shapes, input_types, input_structure, add_to_graph, use_legacy_function, defun_kwargs)\u001b[0m\n\u001b[1;32m    269\u001b[0m         \u001b[0mfn_factory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrace_tf_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdefun_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    270\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 271\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn_factory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    272\u001b[0m     \u001b[0;31m# There is no graph to add in eager mode.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    273\u001b[0m     \u001b[0madd_to_graph\u001b[0m \u001b[0;34m&=\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mget_concrete_function\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3069\u001b[0m     \"\"\"\n\u001b[1;32m   3070\u001b[0m     graph_function = self._get_concrete_function_garbage_collected(\n\u001b[0;32m-> 3071\u001b[0;31m         *args, **kwargs)\n\u001b[0m\u001b[1;32m   3072\u001b[0m     \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_garbage_collector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelease\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3073\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_get_concrete_function_garbage_collected\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3034\u001b[0m       \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3035\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3036\u001b[0;31m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3037\u001b[0m       \u001b[0mseen_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3038\u001b[0m       captured = object_identity.ObjectIdentitySet(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   3290\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3291\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_call_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_context\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3292\u001b[0;31m           \u001b[0mgraph_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3293\u001b[0m           self._function_cache.add(cache_key, cache_key_deletion_observer,\n\u001b[1;32m   3294\u001b[0m                                    graph_function)\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[0;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m   3138\u001b[0m             \u001b[0marg_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0marg_names\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3139\u001b[0m             \u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3140\u001b[0;31m             capture_by_value=self._capture_by_value),\n\u001b[0m\u001b[1;32m   3141\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_attributes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3142\u001b[0m         \u001b[0mfunction_spec\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_spec\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes, acd_record_initial_resource_uses)\u001b[0m\n\u001b[1;32m   1159\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1160\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1161\u001b[0;31m       \u001b[0mfunc_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1162\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1163\u001b[0m       \u001b[0;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/data/ops/structured_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[0;34m(*args)\u001b[0m\n\u001b[1;32m    246\u001b[0m           attributes=defun_kwargs)\n\u001b[1;32m    247\u001b[0m       \u001b[0;32mdef\u001b[0m \u001b[0mwrapped_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=missing-docstring\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 248\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwrapper_helper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    249\u001b[0m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstructure\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_tensor_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output_structure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/data/ops/structured_function.py\u001b[0m in \u001b[0;36mwrapper_helper\u001b[0;34m(*args)\u001b[0m\n\u001b[1;32m    175\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0m_should_unpack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnested_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    176\u001b[0m         \u001b[0mnested_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnested_args\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 177\u001b[0;31m       \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mautograph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtf_convert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag_ctx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mnested_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    178\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0m_should_pack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    687\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    688\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mconversion_ctx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 689\u001b[0;31m           \u001b[0;32mreturn\u001b[0m \u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    690\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    691\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'ag_error_metadata'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36mconverted_call\u001b[0;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[1;32m    375\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    376\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muser_requested\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mconversion\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_allowlisted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 377\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_call_unconverted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    378\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    379\u001b[0m   \u001b[0;31m# internal_convert_user_code is for example turned off when issuing a dynamic\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36m_call_unconverted\u001b[0;34m(f, args, kwargs, options, update_cache)\u001b[0m\n\u001b[1;32m    456\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    457\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 458\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    459\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    460\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36mslice_batch_indices\u001b[0;34m(indices)\u001b[0m\n\u001b[1;32m    311\u001b[0m       \u001b[0mfirst_k_indices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mslice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mnum_in_full_batch\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    312\u001b[0m       first_k_indices = tf.reshape(\n\u001b[0;32m--> 313\u001b[0;31m           first_k_indices, [num_full_batches, batch_size])\n\u001b[0m\u001b[1;32m    314\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    315\u001b[0m       \u001b[0mflat_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_tensor_slices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfirst_k_indices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py\u001b[0m in \u001b[0;36mop_dispatch_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1080\u001b[0m       \u001b[0;31m# Fallback dispatch system (dispatch v1):\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1081\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1082\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mdispatch_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1083\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1084\u001b[0m         \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/array_ops.py\u001b[0m in \u001b[0;36mreshape\u001b[0;34m(tensor, shape, name)\u001b[0m\n\u001b[1;32m    192\u001b[0m     \u001b[0mA\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mHas\u001b[0m \u001b[0mthe\u001b[0m \u001b[0msame\u001b[0m \u001b[0mtype\u001b[0m \u001b[0;32mas\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    193\u001b[0m   \"\"\"\n\u001b[0;32m--> 194\u001b[0;31m   \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgen_array_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    195\u001b[0m   \u001b[0mtensor_util\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmaybe_set_static_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    196\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gen_array_ops.py\u001b[0m in \u001b[0;36mreshape\u001b[0;34m(tensor, shape, name)\u001b[0m\n\u001b[1;32m   8545\u001b[0m   \u001b[0;31m# Add nodes to the TensorFlow graph.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   8546\u001b[0m   _, _, _op, _outputs = _op_def_library._apply_op_helper(\n\u001b[0;32m-> 8547\u001b[0;31m         \"Reshape\", tensor=tensor, shape=shape, name=name)\n\u001b[0m\u001b[1;32m   8548\u001b[0m   \u001b[0m_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   8549\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0m_execute\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmust_record_gradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/op_def_library.py\u001b[0m in \u001b[0;36m_apply_op_helper\u001b[0;34m(op_type_name, name, **keywords)\u001b[0m\n\u001b[1;32m    740\u001b[0m       op = g._create_op_internal(op_type_name, inputs, dtypes=None,\n\u001b[1;32m    741\u001b[0m                                  \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscope\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_types\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_types\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 742\u001b[0;31m                                  attrs=attr_protos, op_def=op_def)\n\u001b[0m\u001b[1;32m    743\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    744\u001b[0m     \u001b[0;31m# `outputs` is returned as a separate return value so that the output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36m_create_op_internal\u001b[0;34m(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_device)\u001b[0m\n\u001b[1;32m    693\u001b[0m     return super(FuncGraph, self)._create_op_internal(  # pylint: disable=protected-access\n\u001b[1;32m    694\u001b[0m         \u001b[0mop_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtypes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_types\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop_def\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 695\u001b[0;31m         compute_device)\n\u001b[0m\u001b[1;32m    696\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    697\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mcapture\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_create_op_internal\u001b[0;34m(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_device)\u001b[0m\n\u001b[1;32m   3782\u001b[0m           \u001b[0minput_types\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_types\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3783\u001b[0m           \u001b[0moriginal_op\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_default_original_op\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3784\u001b[0;31m           op_def=op_def)\n\u001b[0m\u001b[1;32m   3785\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_op_helper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompute_device\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcompute_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3786\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, node_def, g, inputs, output_types, control_inputs, input_types, original_op, op_def)\u001b[0m\n\u001b[1;32m   2170\u001b[0m         \u001b[0mop_def\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_op_def\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2171\u001b[0m       self._c_op = _create_c_op(self._graph, node_def, inputs,\n\u001b[0;32m-> 2172\u001b[0;31m                                 control_input_ops, op_def)\n\u001b[0m\u001b[1;32m   2173\u001b[0m       \u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_str\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2174\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_create_c_op\u001b[0;34m(graph, node_def, inputs, control_inputs, op_def)\u001b[0m\n\u001b[1;32m   2005\u001b[0m     \u001b[0;31m# It might be worth creating a convenient way to re-use the same status.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2006\u001b[0m     pywrap_tf_session.TF_SetAttrValueProto(op_desc, compat.as_str(name),\n\u001b[0;32m-> 2007\u001b[0;31m                                            serialized)\n\u001b[0m\u001b[1;32m   2008\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2009\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We had to abrupty terminate the training at around 658 steps due to insufficient time, so our epsilon decay is midway. But we see the rewards increasing smoothly as the model learns."
      ],
      "metadata": {
        "id": "mVR8JiK9xtqv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Plotting Epsilon Decay DQ-Learning \n",
        "plt.plot(ddql.DDepsilon_decay,mfc='pink') \n",
        "plt.xticks(range(0,len(ddql.DDepsilon_decay)+1, 100)) \n",
        "\n",
        "plt.ylabel('epsilon')\n",
        "plt.xlabel('episodes') \n",
        "plt.title(\"Epsilon Decay DQ-Learning \") \n",
        "plt.show()"
      ],
      "metadata": {
        "id": "QnSNZG6g8geJ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "outputId": "b51621dd-158e-4a5a-aa85-74a2e9d3dfd2"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Reward at each iteration DQ-Learning\n",
        "plt.plot(ddql.ddqn_reward_train) \n",
        "plt.xticks(range(0,len(ddql.ddqn_reward_train)+1, 100)) \n",
        "\n",
        "plt.ylabel('rewards')\n",
        "plt.xlabel('episodes') \n",
        "plt.title(\"Reward at each episodes Q-Learning\") \n",
        "plt.show()"
      ],
      "metadata": {
        "id": "t8TeosHK8h-U",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "outputId": "056dedf1-946b-4954-8703-7673bfe9c459"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#evaluate Q learning\n",
        "gamma = 0.95\n",
        "\n",
        "reward_DQlearning_10ep = []\n",
        "for i in np.arange(10):\n",
        "    obs = ddql.env.reset()\n",
        "    done_iter = False\n",
        "    print(i,end=\"\\r\")\n",
        "    cumm_reward=0\n",
        "    step_no = 0\n",
        "    while not done_iter:\n",
        "        action = int(ddql.greedy_act_max(obs.reshape(1,8)))\n",
        "        obs_next, reward, done_iter, info = ddql.env.step(action)\n",
        "        cumm_reward += (gamma**(step_no))*reward\n",
        "        obs = obs_next\n",
        "        # done_iter = done\n",
        "        step_no += 1\n",
        "    reward_DQlearning_10ep.append(cumm_reward)\n",
        "\n",
        "plt.plot(reward_DQlearning_10ep,color='magenta') \n",
        "plt.xticks(range(0,len(reward_DQlearning_10ep)+1, 1)) \n",
        "\n",
        "plt.ylabel('rewards')\n",
        "plt.xlabel('iteration') \n",
        "plt.title(\"Reward Greedy 10 Episodes of trained DQ-Learning \") \n",
        "plt.show()"
      ],
      "metadata": {
        "id": "X6qO5tAO8jUx",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "outputId": "519216a1-84ad-48d2-8ec0-f64d7f77648a"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ""
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}